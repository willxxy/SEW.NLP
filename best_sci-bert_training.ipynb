{"cells":[{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"cREe6FG_gp1O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653781921249,"user_tz":420,"elapsed":623,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"6f05f488-ba53-469a-f91a-a809a6f5a1a3"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat May 28 23:52:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    34W / 250W |  15993MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"lWXzDb_YAhIw","executionInfo":{"status":"ok","timestamp":1653803459942,"user_tz":420,"elapsed":339,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["import os \n","import pandas as pd \n","import numpy as np\n","import sqlite3"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13893,"status":"ok","timestamp":1653779683984,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"vylq5TdU6qyO","outputId":"9e25df8c-8719-4747-900d-4e9a02270870"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 4.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 4.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.7 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 36.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2350,"status":"ok","timestamp":1653803463227,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"vQByxqDAMo0s","outputId":"bdb61812-1f7e-4308-fe3c-e53455bcfb95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset\n","import torch.nn.functional as F\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import accuracy_score,matthews_corrcoef"],"metadata":{"id":"S7YPcIceOBRr","executionInfo":{"status":"ok","timestamp":1653803464669,"user_tz":420,"elapsed":1448,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"t6ZqEAs05iRo","executionInfo":{"status":"ok","timestamp":1653803470916,"user_tz":420,"elapsed":6250,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["from transformers import AutoModel, AutoTokenizer, AutoModelForQuestionAnswering\n","from sklearn.model_selection import train_test_split\n","\n","\n","df = pd.read_csv('/content/drive/MyDrive/SEW.NLP/qasper_df.csv', index_col=0).drop_duplicates().reset_index(drop=True)\n","intro_papers_df = pd.read_csv('/content/drive/MyDrive/SEW.NLP/intro_papers_df.csv', index_col=0)\n","\n","df[\"introPaper\"], intro_papers_df[\"introPaper\"] = False, True\n","df = pd.concat([df, intro_papers_df], axis=0).reset_index(drop=True)\n","\n","# only keep questions related to the data\n","search_for = [\"data\", \"feature\", \"variable\", \"result\", \"preprocessing\", \"labels\", \"baseline\", \"metric\"]\n","df_filtered = df.loc[df[\"question\"].str.contains(\"|\".join(search_for))]\n","# df_filtered[\"start-end\"] = df_filtered.apply(lambda x: (x[\"start_index\"], x[\"end_index\"]), axis=1)\n","# df_filtered = df_filtered.groupby([\"question\", \"context\"])[\"start-end\"].apply(list).reset_index()"]},{"cell_type":"code","source":["count_answers = df_filtered.groupby([\"question\", \"context\"])[\"answer\"].count().reset_index()\n","context_mult_answers = count_answers[count_answers[\"answer\"] > 1][\"context\"]\n","df_filtered = df_filtered[(df_filtered[\"start_index\"] != -1) | (~df_filtered[\"context\"].isin(context_mult_answers))]"],"metadata":{"id":"Xdp0OyEqEzNo","executionInfo":{"status":"ok","timestamp":1653803470917,"user_tz":420,"elapsed":17,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_filtered[\"min_start_idx\"] = df_filtered.groupby([\"question\", \"context\"])[\"start_index\"].transform(\"min\")\n","df_filtered[\"max_end_idx\"] = df_filtered.groupby([\"question\", \"context\"])[\"end_index\"].transform(\"max\")"],"metadata":{"id":"NuZOhpMDDp3O","executionInfo":{"status":"ok","timestamp":1653803471215,"user_tz":420,"elapsed":314,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"peD2l0PVO6WD","executionInfo":{"status":"ok","timestamp":1653803471216,"user_tz":420,"elapsed":5,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["def narrow_context(row):\n","    context = row[\"context\"]\n","    start_index = max(row[\"min_start_idx\"] - 4000, 0) \n","    end_index = max(row[\"max_end_idx\"] + 4000, 8000)\n","    end_index = min(end_index, len(context)-1)\n","    return context[start_index:end_index]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"mwLe7mLos65I","executionInfo":{"status":"ok","timestamp":1653803471575,"user_tz":420,"elapsed":364,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["df_filtered[\"narrowed_context\"] = df_filtered.apply(narrow_context, axis=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"cSmOK-flP5zZ","executionInfo":{"status":"ok","timestamp":1653803471576,"user_tz":420,"elapsed":4,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["def find_index(row):\n","    answer = row[\"answer\"]\n","    start_index = row[\"narrowed_context\"].find(answer) if row[\"start_index\"] != -1 else -1\n","    end_index = start_index + len(answer) - 1 if row[\"start_index\"] != -1 else -1\n","    return start_index, end_index\n","\n","df_filtered[\"start-end\"] = df_filtered.apply(find_index, axis=1)\n","df_filtered[\"narrowed_context\"] = df_filtered[\"narrowed_context\"].str.strip()\n","df_filtered[\"answer\"] = df_filtered[\"answer\"].str.strip()"]},{"cell_type":"code","source":["df_filtered = df_filtered.groupby([\"question\", \"narrowed_context\"])[[\"start-end\", \"answer\"]].agg(lambda x: list(x)).reset_index()"],"metadata":{"id":"-n0d-1ZlGhn3","executionInfo":{"status":"ok","timestamp":1653803471855,"user_tz":420,"elapsed":8,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["X = df_filtered[['question', 'narrowed_context']]\n","y = df_filtered[[\"start-end\", \"answer\"]]\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n","\n","df_train = pd.concat([X_train, y_train], axis = 1)\n","df_val = pd.concat([X_val, y_val], axis = 1)\n","df_test = pd.concat([X_test, y_test], axis = 1)"],"metadata":{"id":"ToxImKvkHIL2","executionInfo":{"status":"ok","timestamp":1653803471855,"user_tz":420,"elapsed":7,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"GxWPEuifP7A_","executionInfo":{"status":"ok","timestamp":1653803471856,"user_tz":420,"elapsed":7,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)\n","df_test = df_test.reset_index(drop=True)"]},{"cell_type":"code","source":["def tokenize_df(df, tokenizer, MAX_LEN, stride):\n","\n","    return tokenizer(\n","        list(df['question']),\n","        list(df['narrowed_context']),\n","        max_length = MAX_LEN,\n","        return_overflowing_tokens = True,\n","        truncation = 'only_second',\n","        return_offsets_mapping = True,\n","        stride = stride,\n","        padding = 'max_length'\n","    )\n"],"metadata":{"id":"Z61z5llNJ-MI","executionInfo":{"status":"ok","timestamp":1653803471857,"user_tz":420,"elapsed":8,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3CP-DoFniMKP","executionInfo":{"status":"ok","timestamp":1653803472289,"user_tz":420,"elapsed":440,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["def preprocess_data(df, tokenizer, max_len, stride):\n","    start_positions = []\n","    end_positions = []\n","\n","    tokenized = tokenize_df(df, tokenizer, max_len, stride)\n","\n","    offsets_mapping = tokenized[\"offset_mapping\"]\n","    for i, offset in enumerate(offsets_mapping):\n","        sequence_ids = tokenized.sequence_ids(i)\n","        \n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        df_index = tokenized[\"overflow_to_sample_mapping\"][i]\n","        list_start_end = df.loc[df_index, \"start-end\"]\n","        if i == 0:\n","          print(list_start_end, offset[context_start][0], offset[context_end][1])\n","\n","        for start_char, end_char in list_start_end:\n","            if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n","                continue\n","            else:\n","                idx = context_start\n","                while idx <= context_end and offset[idx][0] <= start_char:\n","                    idx += 1\n","                start_positions.append(idx - 1)\n","\n","                idx = context_end\n","                while idx >= context_start and offset[idx][1] >= end_char:\n","                    idx -= 1\n","                end_positions.append(idx + 1)\n","                if i == 0:\n","                    print(start_positions, end_positions)\n","                break\n","        \n","        if len(start_positions) == i:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","    \n","        if i == 0:\n","            print(start_positions, end_positions)\n","\n","    tokenized[\"start_positions\"] = start_positions\n","    tokenized[\"end_positions\"] = end_positions\n","    \n","    return tokenized"]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"ixa-ehu/SciBERT-SQuAD-QuAC\")"],"metadata":{"id":"v47JnQbOK6ok","executionInfo":{"status":"ok","timestamp":1653803479719,"user_tz":420,"elapsed":7432,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["MAX_LEN = 512\n","stride = 128\n","\n","data_preprocessing_pipeline = lambda df: preprocess_data(df, tokenizer, MAX_LEN, stride)\n","\n","df_train_tokenized = data_preprocessing_pipeline(df_train)\n","df_val_tokenized = data_preprocessing_pipeline(df_val)\n","df_test_tokenized = data_preprocessing_pipeline(df_test)"],"metadata":{"id":"YXbPOrXaMYjA","executionInfo":{"status":"ok","timestamp":1653803485020,"user_tz":420,"elapsed":5314,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"251b3fc2-ea81-4c7f-8414-b07845af9716"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[(4000, 4037), (4150, 4209)] 0 1941\n","[0] [0]\n","[(4000, 4002), (4330, 4333), (4590, 4593)] 0 2595\n","[0] [0]\n","[(4000, 4014)] 0 2410\n","[0] [0]\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"id":"7Keu6AN65RX0","executionInfo":{"status":"ok","timestamp":1653803485021,"user_tz":420,"elapsed":16,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["class TextDataset(Dataset):\n","  def __init__(self, questions, starts, ends, attention_masks, df_index, offset_mapping):\n","    self.questions = questions\n","    self.starts = starts\n","    self.ends = ends\n","    self.attention_masks = attention_masks\n","    self.df_index = df_index\n","    self.offset_mapping = offset_mapping\n","\n","  def __len__(self):\n","    return len(self.questions)\n","\n","  def __getitem__(self, item):\n","    question = self.questions[item]\n","    attention_mask = self.attention_masks[item]\n","    start = self.starts[item]\n","    end = self.ends[item]\n","    df_index = self.df_index[item]\n","    offset_mapping = self.offset_mapping[item]\n","\n","\n","    return {\n","      'input_ids': torch.tensor(question, dtype = torch.long),\n","      'attention_mask': torch.tensor(attention_mask, dtype = torch.long),\n","      'start_positions': torch.tensor(start, dtype=torch.long),\n","      'end_positions' : torch.tensor(end, dtype = torch.long),\n","      'df_index': torch.tensor(df_index, dtype=torch.long),\n","      'offset_mapping': offset_mapping\n","    }"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"UOioYhl3HD8A","executionInfo":{"status":"ok","timestamp":1653803485022,"user_tz":420,"elapsed":16,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["train_dataset = TextDataset(\n","    questions = df_train_tokenized['input_ids'],\n","    starts = df_train_tokenized['start_positions'],\n","    ends = df_train_tokenized['end_positions'],\n","    attention_masks = df_train_tokenized['attention_mask'],\n","    df_index = df_train_tokenized[\"overflow_to_sample_mapping\"],\n","    offset_mapping = df_train_tokenized[\"offset_mapping\"]\n",")\n","\n","val_dataset = TextDataset(\n","    questions = df_val_tokenized['input_ids'],\n","    starts = df_val_tokenized['start_positions'],\n","    ends = df_val_tokenized['end_positions'],\n","    attention_masks = df_val_tokenized['attention_mask'],\n","    df_index = df_val_tokenized[\"overflow_to_sample_mapping\"],\n","    offset_mapping = df_val_tokenized[\"offset_mapping\"]\n",")\n","\n","test_dataset = TextDataset(\n","    questions = df_test_tokenized['input_ids'],\n","    starts = df_test_tokenized['start_positions'],\n","    ends = df_test_tokenized['end_positions'],\n","    attention_masks = df_test_tokenized['attention_mask'],\n","    df_index = df_test_tokenized[\"overflow_to_sample_mapping\"],\n","    offset_mapping = df_test_tokenized[\"offset_mapping\"]\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"TRyz7LkCpOen","executionInfo":{"status":"ok","timestamp":1653804603804,"user_tz":420,"elapsed":294,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["batch_size = 8\n","\n","\n","# train_sampler = RandomSampler(train_data)\n","# val_sampler = RandomSampler(val_data)\n","# test_sampler = RandomSampler(test_data)\n","\n","# train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n","# val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n","# test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Dowik7NKr89L","executionInfo":{"status":"ok","timestamp":1653804607406,"user_tz":420,"elapsed":768,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["import gc\n","gc.collect()\n","import torch\n","torch.cuda.empty_cache()\n","import random\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)\n","\n","SEED = 19\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if device == torch.device(\"cuda\"):\n","    torch.cuda.manual_seed_all(SEED)\n","\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"Ijuz53S3ugwq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653806318806,"user_tz":420,"elapsed":2970,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"5a0ba7d4-28a9-4fc3-90df-3fb04fc26c83"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/ixa-ehu/SciBERT-SQuAD-QuAC/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a8c52b63ffbb5c867d6270ae21e7905d08e9801af48232ff0e08e3b755da233b.7c3af56d16d03847a339f67a41d8e0c1108d55c0977344615e38b438ec54680d\n","Model config BertConfig {\n","  \"_name_or_path\": \"ixa-ehu/SciBERT-SQuAD-QuAC\",\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading weights file https://huggingface.co/ixa-ehu/SciBERT-SQuAD-QuAC/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/be1f037bb6f580098db99a74b56f047197796f8bfe208adedc38535a3375b3b4.f2bbdc825305b85292391508b969d6ba7727d7f6a6dad6303eddbd1e7c918e80\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ixa-ehu/SciBERT-SQuAD-QuAC.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["from transformers import TrainingArguments, Trainer\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"ixa-ehu/SciBERT-SQuAD-QuAC\").to(device)\n","model_checkpoint = \"ixa-ehu/SciBERT-SQuAD-QuAC\"\n","\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    output_dir = \"/content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_dir = \"./logs/runs\",\n","    do_train = True,\n","    do_eval = True,\n","    learning_rate=3e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_accumulation_steps=4,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    logging_steps = 25\n","\n",")"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"guDJ_GU8v1IR","executionInfo":{"status":"ok","timestamp":1653806320617,"user_tz":420,"elapsed":294,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[],"source":["from transformers import default_data_collator\n","\n","data_collator = default_data_collator\n","\n","\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= val_dataset,\n","    data_collator=data_collator\n",")"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"lEle2e9gyZEx","colab":{"base_uri":"https://localhost:8080/","height":714},"outputId":"255fdfc3-1071-42cd-e622-b7f2fd43df13","executionInfo":{"status":"ok","timestamp":1653806953330,"user_tz":420,"elapsed":631615,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5660\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 354\n","The following columns in the training set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='354' max='354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [354/354 10:29, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.233000</td>\n","      <td>1.308563</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.958600</td>\n","      <td>1.375567</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 702\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n","Saving model checkpoint to /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177\n","Configuration saved in /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177/config.json\n","Model weights saved in /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 702\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n","Saving model checkpoint to /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-354\n","Configuration saved in /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-354/config.json\n","Model weights saved in /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-354/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 10min 27s, sys: 3.06 s, total: 10min 30s\n","Wall time: 10min 31s\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=354, training_loss=1.2174749381124637, metrics={'train_runtime': 631.5325, 'train_samples_per_second': 17.925, 'train_steps_per_second': 0.561, 'total_flos': 2957879286251520.0, 'train_loss': 1.2174749381124637, 'epoch': 2.0})"]},"metadata":{},"execution_count":51}],"source":["%%time\n","trainer.train()"]},{"cell_type":"code","source":["# current best \"/content/drive/MyDrive/SEW.NLP/logs/scibert_squad_15/checkpoint-500\"\n","\n","PATH_MODEL = \"/content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177\" # path of model saved at best epoch"],"metadata":{"id":"Ea8e5Zpb_BiO","executionInfo":{"status":"ok","timestamp":1653806968751,"user_tz":420,"elapsed":299,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","execution_count":53,"metadata":{"id":"7c30AOAeG0Ut","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653806972158,"user_tz":420,"elapsed":2377,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"dc41953a-6a19-4109-e52f-6fcc2d317dd9"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177\",\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading weights file /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"]}],"source":["best_model = AutoModelForQuestionAnswering.from_pretrained(PATH_MODEL)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"Vhr8SXNYIb1y","executionInfo":{"status":"ok","timestamp":1653806984870,"user_tz":420,"elapsed":12719,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"colab":{"base_uri":"https://localhost:8080/","height":126},"outputId":"785e335d-ce6a-4d02-8c57-e69858f0b403"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 702\n","  Batch size = 8\n","The following columns in the test set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [88/88 00:12]\n","    </div>\n","    "]},"metadata":{}}],"source":["best_trainer = Trainer(\n","    best_model,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= test_dataset,\n","    data_collator=data_collator\n",")\n","\n","val_predictions = best_trainer.predict(val_dataset)"]},{"cell_type":"code","source":["def compute_best_prediction(start_indexes, end_indexes,\n","                            start_logits, end_logits,\n","                            sequence_ids, offset_mapping, context):\n","    \"\"\"\n","      Computes best feasible prediction and compares it with null prediction\n","    \"\"\"\n","\n","\n","    best_score, null_score = -np.inf, -np.inf\n","    best_answer = \"\"\n","    best_start, best_end = 0, 0\n","\n","    \n","    for start_index in start_indexes:\n","        for end_index in end_indexes:\n","            score = start_logits[start_index] + end_logits[end_index]\n","            if start_index == 0 or end_index == 0: # null prediction\n","                if start_index != end_index:\n","                    continue\n","                null_score = score\n","            \n","            elif start_index <= end_index and sequence_ids[start_index] == 1 and sequence_ids[end_index] == 1:\n","                if score > best_score:\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    if end_char > 0:\n","                        best_answer = context[start_char:end_char]\n","                        best_score = score\n","                        best_start = start_index\n","                        best_end = end_index\n","    \n","    score_diff = null_score - best_score\n","    \n","\n","    return {\n","        \"score_diff\": score_diff,\n","        \"pred_start\": best_start,\n","        \"pred_end\": best_end,\n","        \"pred_answer\": best_answer\n","    }"],"metadata":{"id":"8-POH0MvhqyG","executionInfo":{"status":"ok","timestamp":1653806986185,"user_tz":420,"elapsed":280,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["def get_preds_df(predictions, df, tokenized_df, dataset):\n","    predicted_answers = []\n","    n_best_size = 20\n","\n","    test_start_logits, test_end_logits = predictions.predictions\n","    start_labels, end_labels = predictions.label_ids\n","\n","    for i in range(len(dataset)):\n","\n","        start_label, end_label = start_labels[i], end_labels[i]\n","        start_logits, end_logits = test_start_logits[i], test_end_logits[i]\n","\n","        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","\n","        row_idx = dataset[i][\"df_index\"].item()\n","        row_context = df.loc[row_idx, \"narrowed_context\"]\n","        offset_mapping = dataset[i][\"offset_mapping\"]\n","        sequence_ids = tokenized_df.sequence_ids(i)\n","        \n","        # find predicted answer:\n","        prediction = compute_best_prediction(start_indexes, end_indexes, start_logits, end_logits, sequence_ids, offset_mapping, row_context)\n","        \n","        # find correct answer:\n","        start_char_true = offset_mapping[start_label][0]\n","        end_char_true = offset_mapping[end_label][1]\n","        correct_answer = row_context[start_char_true:end_char_true+1] if end_label > 0 else \"\"\n","        \n","        prediction[\"pred_token\"] = tokenized_df[i].tokens[prediction[\"pred_start\"]:prediction[\"pred_end\"]+1]\n","        prediction[\"start_label\"] = start_label\n","        prediction[\"end_label\"] = end_label\n","        prediction[\"correct_answer\"] = correct_answer\n","        prediction[\"correct_token\"] = tokenized_df[i].tokens[start_label:end_label+1]\n","\n","        predicted_answers.append(prediction)\n","\n","    preds_df = pd.DataFrame(predicted_answers)\n","    preds_df[\"NoAnsw\"] = preds_df.apply(lambda row: row[\"correct_token\"] == [\"[CLS]\"], axis=1)\n","    \n","    return preds_df"],"metadata":{"id":"DnfXJYoYmFDg","executionInfo":{"status":"ok","timestamp":1653806987378,"user_tz":420,"elapsed":292,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["val_preds_df = get_preds_df(val_predictions, df_val, df_val_tokenized, val_dataset)"],"metadata":{"id":"LgLJSZ8oD83P","executionInfo":{"status":"ok","timestamp":1653806989119,"user_tz":420,"elapsed":711,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["val_preds_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"lgcXn-i45oJo","executionInfo":{"status":"ok","timestamp":1653806990183,"user_tz":420,"elapsed":7,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"b2884744-0024-4006-fb7d-aaa4b1b50050"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     score_diff  pred_start  pred_end  \\\n","0      6.430604         103       110   \n","1     -3.744671         407       407   \n","2     -4.712158          34       105   \n","3      1.418314         132       134   \n","4      8.940039          35        40   \n","..          ...         ...       ...   \n","697    4.413710         106       107   \n","698   -4.167419         480       497   \n","699   -2.804528          99       114   \n","700    9.570248          57       478   \n","701   11.585387          95        98   \n","\n","                                           pred_answer  \\\n","0                          hoax, propaganda and satire   \n","1                                                  CNN   \n","2    CNN: In this model, we apply a 1-d CNN (Convol...   \n","3                          graph convolutional network   \n","4                                   GAT + 2 Attn Heads   \n","..                                                 ...   \n","697                                            perplex   \n","698  EM INLINEFORM0 : evaluates the overall accurac...   \n","699  leftmargin=*] EM INLINEFORM0 : evaluates the o...   \n","700  HiStGen INLINEFORM7 gives the worst performanc...   \n","701              Markov paragraph dependency mechanism   \n","\n","                                            pred_token  start_label  \\\n","0       [ho, ##ax, ,, propag, ##anda, and, sati, ##re]            0   \n","1                                                [cnn]          407   \n","2    [cnn, :, in, this, model, ,, we, apply, a, 1, ...           34   \n","3                      [graph, convolutional, network]            0   \n","4                         [gat, +, 2, att, ##n, heads]            0   \n","..                                                 ...          ...   \n","697                                      [per, ##plex]            0   \n","698  [em, in, ##line, ##form, ##0, :, evaluates, th...          480   \n","699  [left, ##mar, ##gin, =, *, ], em, in, ##line, ...          105   \n","700  [hist, ##gen, in, ##line, ##form, ##7, gives, ...            0   \n","701         [markov, paragraph, dependency, mechanism]            0   \n","\n","     end_label   correct_answer                  correct_token  NoAnsw  \n","0            0                                         [[CLS]]    True  \n","1          407             CNN:                          [cnn]   False  \n","2           34             CNN:                          [cnn]   False  \n","3            0                                         [[CLS]]    True  \n","4            0                                         [[CLS]]    True  \n","..         ...              ...                            ...     ...  \n","697          0                                         [[CLS]]    True  \n","698        484  EM INLINEFORM0   [em, in, ##line, ##form, ##0]   False  \n","699        109  EM INLINEFORM0   [em, in, ##line, ##form, ##0]   False  \n","700          0                                         [[CLS]]    True  \n","701          0                                         [[CLS]]    True  \n","\n","[702 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-342e97d9-d5e4-450d-b68c-73efbd48c8ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score_diff</th>\n","      <th>pred_start</th>\n","      <th>pred_end</th>\n","      <th>pred_answer</th>\n","      <th>pred_token</th>\n","      <th>start_label</th>\n","      <th>end_label</th>\n","      <th>correct_answer</th>\n","      <th>correct_token</th>\n","      <th>NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.430604</td>\n","      <td>103</td>\n","      <td>110</td>\n","      <td>hoax, propaganda and satire</td>\n","      <td>[ho, ##ax, ,, propag, ##anda, and, sati, ##re]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>[[CLS]]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-3.744671</td>\n","      <td>407</td>\n","      <td>407</td>\n","      <td>CNN</td>\n","      <td>[cnn]</td>\n","      <td>407</td>\n","      <td>407</td>\n","      <td>CNN:</td>\n","      <td>[cnn]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-4.712158</td>\n","      <td>34</td>\n","      <td>105</td>\n","      <td>CNN: In this model, we apply a 1-d CNN (Convol...</td>\n","      <td>[cnn, :, in, this, model, ,, we, apply, a, 1, ...</td>\n","      <td>34</td>\n","      <td>34</td>\n","      <td>CNN:</td>\n","      <td>[cnn]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.418314</td>\n","      <td>132</td>\n","      <td>134</td>\n","      <td>graph convolutional network</td>\n","      <td>[graph, convolutional, network]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>[[CLS]]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8.940039</td>\n","      <td>35</td>\n","      <td>40</td>\n","      <td>GAT + 2 Attn Heads</td>\n","      <td>[gat, +, 2, att, ##n, heads]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>[[CLS]]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>697</th>\n","      <td>4.413710</td>\n","      <td>106</td>\n","      <td>107</td>\n","      <td>perplex</td>\n","      <td>[per, ##plex]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>[[CLS]]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>698</th>\n","      <td>-4.167419</td>\n","      <td>480</td>\n","      <td>497</td>\n","      <td>EM INLINEFORM0 : evaluates the overall accurac...</td>\n","      <td>[em, in, ##line, ##form, ##0, :, evaluates, th...</td>\n","      <td>480</td>\n","      <td>484</td>\n","      <td>EM INLINEFORM0</td>\n","      <td>[em, in, ##line, ##form, ##0]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>-2.804528</td>\n","      <td>99</td>\n","      <td>114</td>\n","      <td>leftmargin=*] EM INLINEFORM0 : evaluates the o...</td>\n","      <td>[left, ##mar, ##gin, =, *, ], em, in, ##line, ...</td>\n","      <td>105</td>\n","      <td>109</td>\n","      <td>EM INLINEFORM0</td>\n","      <td>[em, in, ##line, ##form, ##0]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>700</th>\n","      <td>9.570248</td>\n","      <td>57</td>\n","      <td>478</td>\n","      <td>HiStGen INLINEFORM7 gives the worst performanc...</td>\n","      <td>[hist, ##gen, in, ##line, ##form, ##7, gives, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>[[CLS]]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>701</th>\n","      <td>11.585387</td>\n","      <td>95</td>\n","      <td>98</td>\n","      <td>Markov paragraph dependency mechanism</td>\n","      <td>[markov, paragraph, dependency, mechanism]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>[[CLS]]</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>702 rows × 10 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-342e97d9-d5e4-450d-b68c-73efbd48c8ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-342e97d9-d5e4-450d-b68c-73efbd48c8ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-342e97d9-d5e4-450d-b68c-73efbd48c8ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["import collections\n","\n","def compute_f1(gold_toks, pred_toks):\n","    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","    num_same = sum(common.values())\n","    if len(gold_toks) == 0 or len(pred_toks) == 0:\n","        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","        return int(gold_toks == pred_toks)\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(pred_toks)\n","    recall = 1.0 * num_same / len(gold_toks)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"],"metadata":{"id":"6a8IdclX0NCc","executionInfo":{"status":"ok","timestamp":1653807018034,"user_tz":420,"elapsed":3,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def get_f1_df(preds_df):\n","    f1_data = {\"threshold\": [], \"f1\":[], \"f1_Answ\":[], \"f1_NoAnsw\":[]}\n","\n","    for threshold in np.arange(-3, 10, 1):\n","        temp = preds_df.copy()\n","        temp[\"pred_token\"] = temp.apply(lambda row: row[\"pred_token\"] if row[\"score_diff\"] < threshold else [\"[CLS]\"], axis=1)\n","        temp[\"f1\"] = temp.apply(lambda r: compute_f1(r[\"correct_token\"], r[\"pred_token\"]), axis=1)\n","\n","        f1_total = 100 * np.mean(temp[\"f1\"])\n","        f1_scores = list(100 * temp.groupby(\"NoAnsw\").agg([\"mean\"])[\"f1\"][\"mean\"])\n","        \n","        f1_data[\"threshold\"].append(threshold)\n","        f1_data[\"f1\"].append(f1_total)\n","        f1_data[\"f1_Answ\"].append(f1_scores[0])\n","        f1_data[\"f1_NoAnsw\"].append(f1_scores[1])\n","\n","    df_scores = pd.DataFrame(f1_data)\n","\n","    return df_scores\n","val_scores = get_f1_df(val_preds_df)"],"metadata":{"id":"uGUyIeK60f1U","executionInfo":{"status":"ok","timestamp":1653807020198,"user_tz":420,"elapsed":724,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["val_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"UQ9-n1VocNsT","executionInfo":{"status":"ok","timestamp":1653807020564,"user_tz":420,"elapsed":7,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"b81a5dfa-46b9-49ed-c121-bdf650005ee5"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    threshold         f1    f1_Answ  f1_NoAnsw\n","0          -3  72.627485  16.596821  98.541667\n","1          -2  73.650332  21.633031  97.708333\n","2          -1  73.477952  23.790641  96.458333\n","3           0  73.349747  26.988841  94.791667\n","4           1  72.823506  29.829286  92.708333\n","5           2  71.629492  34.612178  88.750000\n","6           3  70.125980  37.515488  85.208333\n","7           4  66.323394  39.004605  78.958333\n","8           5  64.523352  42.321589  74.791667\n","9           6  60.555474  42.837580  68.750000\n","10          7  55.981057  43.687847  61.666667\n","11          8  51.736914  44.681593  55.000000\n","12          9  47.271421  45.425844  48.125000"],"text/html":["\n","  <div id=\"df-81783338-8239-41e2-985d-dcb94ddd242d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>f1</th>\n","      <th>f1_Answ</th>\n","      <th>f1_NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-3</td>\n","      <td>72.627485</td>\n","      <td>16.596821</td>\n","      <td>98.541667</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-2</td>\n","      <td>73.650332</td>\n","      <td>21.633031</td>\n","      <td>97.708333</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1</td>\n","      <td>73.477952</td>\n","      <td>23.790641</td>\n","      <td>96.458333</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>73.349747</td>\n","      <td>26.988841</td>\n","      <td>94.791667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>72.823506</td>\n","      <td>29.829286</td>\n","      <td>92.708333</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>71.629492</td>\n","      <td>34.612178</td>\n","      <td>88.750000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>70.125980</td>\n","      <td>37.515488</td>\n","      <td>85.208333</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4</td>\n","      <td>66.323394</td>\n","      <td>39.004605</td>\n","      <td>78.958333</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>64.523352</td>\n","      <td>42.321589</td>\n","      <td>74.791667</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>6</td>\n","      <td>60.555474</td>\n","      <td>42.837580</td>\n","      <td>68.750000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>7</td>\n","      <td>55.981057</td>\n","      <td>43.687847</td>\n","      <td>61.666667</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>8</td>\n","      <td>51.736914</td>\n","      <td>44.681593</td>\n","      <td>55.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>9</td>\n","      <td>47.271421</td>\n","      <td>45.425844</td>\n","      <td>48.125000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81783338-8239-41e2-985d-dcb94ddd242d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81783338-8239-41e2-985d-dcb94ddd242d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81783338-8239-41e2-985d-dcb94ddd242d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["val_scores.to_csv(\"/content/drive/MyDrive/SEW.NLP/Edoardo_val_scibert_21.csv\")"],"metadata":{"id":"eBpEVe3GnpP7","executionInfo":{"status":"ok","timestamp":1653804556602,"user_tz":420,"elapsed":267,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["## Pick a threshold with decent f1 and good f1_Answ, like 3 or 4\n","threshold = 4"],"metadata":{"id":"rHlLsT7tDMQE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_trainer = Trainer(\n","    best_model,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= test_dataset,\n","    data_collator=data_collator\n",")\n","\n","test_predictions = best_trainer.predict(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"oH6Ll42RDi-V","executionInfo":{"status":"ok","timestamp":1653776119555,"user_tz":420,"elapsed":28879,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"dc2f3763-0084-4ce6-efb8-9dc0ad6cd660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 1724\n","  Batch size = 20\n","The following columns in the test set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: df_index, offset_mapping. If df_index, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [87/87 00:28]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["test_preds_df = get_preds_df(test_predictions, df_test, df_test_tokenized, test_dataset)"],"metadata":{"id":"tcFIoknpEd0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_scores = get_f1_df(test_preds_df)"],"metadata":{"id":"0dOgCocREtim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_scores[test_scores[\"threshold\"] == threshold] # final score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"KkADOWvFEyGn","executionInfo":{"status":"ok","timestamp":1653776127802,"user_tz":420,"elapsed":160,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"e35ea514-5c28-431e-d914-2874165e3180"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   threshold         f1    f1_Answ  f1_NoAnsw\n","7          4  70.543183  33.574426  84.931507"],"text/html":["\n","  <div id=\"df-c24bf5b7-4a19-46ad-9472-ea4b949f135f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>f1</th>\n","      <th>f1_Answ</th>\n","      <th>f1_NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>4</td>\n","      <td>70.543183</td>\n","      <td>33.574426</td>\n","      <td>84.931507</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c24bf5b7-4a19-46ad-9472-ea4b949f135f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c24bf5b7-4a19-46ad-9472-ea4b949f135f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c24bf5b7-4a19-46ad-9472-ea4b949f135f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":[""],"metadata":{"id":"QKPOkCIeeEyu"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Copia di sci-bert_training.ipynb","provenance":[{"file_id":"1EVPTX2fO7ET_a7OwcQi2CY1NUgSeHrwy","timestamp":1653779631955},{"file_id":"1fvT8jxYiOjv8S4Mnv5N1M67clU6-GOU5","timestamp":1653682438830},{"file_id":"1XIE0_DsKuta5PQKznSOgJ7hc-wN3q7AO","timestamp":1653456595226}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}