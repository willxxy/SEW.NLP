{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":623,"status":"ok","timestamp":1653781921249,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"cREe6FG_gp1O","outputId":"6f05f488-ba53-469a-f91a-a809a6f5a1a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat May 28 23:52:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    34W / 250W |  15993MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWXzDb_YAhIw"},"outputs":[],"source":["import os \n","import pandas as pd \n","import numpy as np\n","import sqlite3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9673,"status":"ok","timestamp":1653866937781,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"vylq5TdU6qyO","outputId":"2f94c38b-38d3-4aa6-9dc6-d6262e5e0d21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 4.2 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 66.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 73.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20323,"status":"ok","timestamp":1653866901658,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"vQByxqDAMo0s","outputId":"efd83c1b-b4fb-4b40-f474-b2f131b9a381"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7YPcIceOBRr"},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset\n","import torch.nn.functional as F\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import accuracy_score,matthews_corrcoef"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6ZqEAs05iRo"},"outputs":[],"source":["from transformers import AutoModel, AutoTokenizer, AutoModelForQuestionAnswering\n","from sklearn.model_selection import train_test_split\n","\n","\n","df = pd.read_csv('/content/drive/MyDrive/SEW.NLP/qasper_df.csv', index_col=0).drop_duplicates().reset_index(drop=True)\n","intro_papers_df = pd.read_csv('/content/drive/MyDrive/SEW.NLP/intro_papers_df.csv', index_col=0)\n","\n","df[\"introPaper\"], intro_papers_df[\"introPaper\"] = False, True\n","df = pd.concat([df, intro_papers_df], axis=0).reset_index(drop=True)\n","\n","# only keep questions related to the data\n","search_for = [\"data\", \"feature\", \"variable\", \"result\", \"preprocessing\", \"labels\", \"baseline\", \"metric\"]\n","df_filtered = df.loc[df[\"question\"].str.contains(\"|\".join(search_for))]\n","# df_filtered[\"start-end\"] = df_filtered.apply(lambda x: (x[\"start_index\"], x[\"end_index\"]), axis=1)\n","# df_filtered = df_filtered.groupby([\"question\", \"context\"])[\"start-end\"].apply(list).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xdp0OyEqEzNo"},"outputs":[],"source":["count_answers = df_filtered.groupby([\"question\", \"context\"])[\"answer\"].count().reset_index()\n","context_mult_answers = count_answers[count_answers[\"answer\"] > 1][\"context\"]\n","df_filtered = df_filtered[(df_filtered[\"start_index\"] != -1) | (~df_filtered[\"context\"].isin(context_mult_answers))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuZOhpMDDp3O"},"outputs":[],"source":["df_filtered[\"min_start_idx\"] = df_filtered.groupby([\"question\", \"context\"])[\"start_index\"].transform(\"min\")\n","df_filtered[\"max_end_idx\"] = df_filtered.groupby([\"question\", \"context\"])[\"end_index\"].transform(\"max\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peD2l0PVO6WD"},"outputs":[],"source":["def narrow_context(row):\n","    context = row[\"context\"]\n","    start_index = max(row[\"min_start_idx\"] - 4000, 0) \n","    end_index = max(row[\"max_end_idx\"] + 4000, 8000)\n","    end_index = min(end_index, len(context)-1)\n","    return context[start_index:end_index]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwLe7mLos65I"},"outputs":[],"source":["df_filtered[\"narrowed_context\"] = df_filtered.apply(narrow_context, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSmOK-flP5zZ"},"outputs":[],"source":["def find_index(row):\n","    answer = row[\"answer\"]\n","    start_index = row[\"narrowed_context\"].find(answer) if row[\"start_index\"] != -1 else -1\n","    end_index = start_index + len(answer) - 1 if row[\"start_index\"] != -1 else -1\n","    return start_index, end_index\n","\n","df_filtered[\"start-end\"] = df_filtered.apply(find_index, axis=1)\n","df_filtered[\"narrowed_context\"] = df_filtered[\"narrowed_context\"].str.strip()\n","df_filtered[\"answer\"] = df_filtered[\"answer\"].str.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-n0d-1ZlGhn3"},"outputs":[],"source":["df_filtered = df_filtered.groupby([\"question\", \"narrowed_context\"])[[\"start-end\", \"answer\"]].agg(lambda x: list(x)).reset_index()"]},{"cell_type":"code","source":["figure, ax = plt.subplots(nrows=1, ncols=1, figsize=(13,5))\n","ax.title.set_text(\"Most common questions\")\n","df_filtered[\"question\"].value_counts().head(10)[-1::-1].plot.barh(width=0.9, color=[\"blue\", \"blue\", \"blue\", \"blue\", \"blue\",\n","                                                                                    \"blue\", \"blue\", \"red\", \"red\", \"red\"])\n","ax.grid()\n","ax.set_axisbelow(True)\n","ax.set_xticks(np.arange(0, 19, 2))\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"X73l8RjRJ2Jv","executionInfo":{"status":"ok","timestamp":1653871596601,"user_tz":420,"elapsed":343,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"259075d8-e08e-4ca8-f6a8-5a5102744be6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 936x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["df_filtered[\"question\"].value_counts()[-1::-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lS1wrEDUVn50","executionInfo":{"status":"ok","timestamp":1653870114790,"user_tz":420,"elapsed":305,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"ffbc634e-6a6d-4181-d06c-4cc949290b25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["why do they think sentiment features do not result in improvement?     1\n","What baseline is used for the experimental setup?                      1\n","What baseline function is used in REINFORCE algorithm?                 1\n","What baseline do they compare against?                                 1\n","What baseline did they use?                                            1\n","                                                                      ..\n","What is the size of the dataset?                                      11\n","Do they report results only on English data?                          11\n","For what purpose was the dataset created?                             12\n","What does the dataset represent?                                      14\n","Which dataset do they use?                                            18\n","Name: question, Length: 980, dtype: int64"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":[""],"metadata":{"id":"X02KNGXvUW-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_filtered"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"0rVqTYDrK1YT","executionInfo":{"status":"ok","timestamp":1653867246359,"user_tz":420,"elapsed":751,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"c79f30fc-8eaa-405d-c816-c152bd3b1648"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               question  \\\n","0     Are answers in this dataset guaranteed to be s...   \n","1     Are reddit and twitter datasets, which are fai...   \n","2     Are there elements, other than pitch, that can...   \n","3     Based on this paper, what is the more predicti...   \n","4                  By how much did the results improve?   \n","...                                                 ...   \n","1286  which non-english language was the had the wor...   \n","1287                   which public datasets were used?   \n","1288  which social media platforms was the data coll...   \n","1289                     who annotated the new dataset?   \n","1290  why do they think sentiment features do not re...   \n","\n","                                       narrowed_context  \\\n","0     This paper describes our submission to the 201...   \n","1     Real world data differs radically from the ben...   \n","2     Singing voice conversion is to convert a singe...   \n","3     hat are considered trustworthy by independent ...   \n","4     The rise of social media is enabling people to...   \n","...                                                 ...   \n","1286  Sentiment analysis is a widely studied NLP tas...   \n","1287  INLINEFORM8 ( INLINEFORM9 ) can be rewritten a...   \n","1288  as following manner. Section SECREF2 describes...   \n","1289  nvestigating the shortcomings of previously re...   \n","1290  following surface-form features were used:   I...   \n","\n","                                              start-end  \\\n","0                                            [(-1, -1)]   \n","1                                            [(-1, -1)]   \n","2                                            [(-1, -1)]   \n","3                                        [(4000, 4045)]   \n","4                                            [(-1, -1)]   \n","...                                                 ...   \n","1286                                       [(795, 801)]   \n","1287  [(4000, 4008), (4021, 4039), (4045, 4071), (46...   \n","1288                                     [(4000, 4006)]   \n","1289         [(4000, 4017), (4752, 4834), (4949, 5047)]   \n","1290                                     [(4000, 4066)]   \n","\n","                                                 answer  \n","0                                                    []  \n","1                                                    []  \n","2                                                    []  \n","3      [words embeddings, style, and morality features]  \n","4                                                    []  \n","...                                                 ...  \n","1286                                          [Turkish]  \n","1287  [CMRC-2017, People's Daily (PD), Children Fair...  \n","1288                                          [Twitter]  \n","1289  [automatic labeling, lemmatization of the abst...  \n","1290  [did not observe any improvement in the cross-...  \n","\n","[1291 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-2a6653c7-de40-493c-974c-a13f7fa854fd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>narrowed_context</th>\n","      <th>start-end</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Are answers in this dataset guaranteed to be s...</td>\n","      <td>This paper describes our submission to the 201...</td>\n","      <td>[(-1, -1)]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Are reddit and twitter datasets, which are fai...</td>\n","      <td>Real world data differs radically from the ben...</td>\n","      <td>[(-1, -1)]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Are there elements, other than pitch, that can...</td>\n","      <td>Singing voice conversion is to convert a singe...</td>\n","      <td>[(-1, -1)]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Based on this paper, what is the more predicti...</td>\n","      <td>hat are considered trustworthy by independent ...</td>\n","      <td>[(4000, 4045)]</td>\n","      <td>[words embeddings, style, and morality features]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>By how much did the results improve?</td>\n","      <td>The rise of social media is enabling people to...</td>\n","      <td>[(-1, -1)]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1286</th>\n","      <td>which non-english language was the had the wor...</td>\n","      <td>Sentiment analysis is a widely studied NLP tas...</td>\n","      <td>[(795, 801)]</td>\n","      <td>[Turkish]</td>\n","    </tr>\n","    <tr>\n","      <th>1287</th>\n","      <td>which public datasets were used?</td>\n","      <td>INLINEFORM8 ( INLINEFORM9 ) can be rewritten a...</td>\n","      <td>[(4000, 4008), (4021, 4039), (4045, 4071), (46...</td>\n","      <td>[CMRC-2017, People's Daily (PD), Children Fair...</td>\n","    </tr>\n","    <tr>\n","      <th>1288</th>\n","      <td>which social media platforms was the data coll...</td>\n","      <td>as following manner. Section SECREF2 describes...</td>\n","      <td>[(4000, 4006)]</td>\n","      <td>[Twitter]</td>\n","    </tr>\n","    <tr>\n","      <th>1289</th>\n","      <td>who annotated the new dataset?</td>\n","      <td>nvestigating the shortcomings of previously re...</td>\n","      <td>[(4000, 4017), (4752, 4834), (4949, 5047)]</td>\n","      <td>[automatic labeling, lemmatization of the abst...</td>\n","    </tr>\n","    <tr>\n","      <th>1290</th>\n","      <td>why do they think sentiment features do not re...</td>\n","      <td>following surface-form features were used:   I...</td>\n","      <td>[(4000, 4066)]</td>\n","      <td>[did not observe any improvement in the cross-...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1291 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a6653c7-de40-493c-974c-a13f7fa854fd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2a6653c7-de40-493c-974c-a13f7fa854fd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2a6653c7-de40-493c-974c-a13f7fa854fd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["len(df_filtered[\"question\"].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xew7f2mSLckW","executionInfo":{"status":"ok","timestamp":1653867425496,"user_tz":420,"elapsed":272,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"323672cc-b2dd-4ea5-b2c3-17252d4756f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["980"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ToxImKvkHIL2"},"outputs":[],"source":["X = df_filtered[['question', 'narrowed_context']]\n","y = df_filtered[[\"start-end\", \"answer\"]]\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)\n","\n","df_train = pd.concat([X_train, y_train], axis = 1)\n","df_val = pd.concat([X_val, y_val], axis = 1)\n","df_test = pd.concat([X_test, y_test], axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GxWPEuifP7A_"},"outputs":[],"source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)\n","df_test = df_test.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z61z5llNJ-MI"},"outputs":[],"source":["def tokenize_df(df, tokenizer, MAX_LEN, stride):\n","\n","    return tokenizer(\n","        list(df['question']),\n","        list(df['narrowed_context']),\n","        max_length = MAX_LEN,\n","        return_overflowing_tokens = True,\n","        truncation = 'only_second',\n","        return_offsets_mapping = True,\n","        stride = stride,\n","        padding = 'max_length'\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CP-DoFniMKP"},"outputs":[],"source":["def preprocess_data(df, tokenizer, max_len, stride):\n","    start_positions = []\n","    end_positions = []\n","\n","    tokenized = tokenize_df(df, tokenizer, max_len, stride)\n","\n","    offsets_mapping = tokenized[\"offset_mapping\"]\n","    for i, offset in enumerate(offsets_mapping):\n","        sequence_ids = tokenized.token_type_ids[i]\n","        \n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 2\n","\n","        df_index = tokenized[\"overflow_to_sample_mapping\"][i]\n","        list_start_end = df.loc[df_index, \"start-end\"]\n","        if i == 774:\n","          print(list_start_end, context_start, context_end, df_index, offset[context_start][0], offset[context_end][1])\n","\n","        for start_char, end_char in list_start_end:\n","            if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n","                continue\n","            elif offset[context_start][0] > start_char:\n","                continue\n","            else:\n","                idx = context_start\n","                while idx <= context_end and offset[idx][0] <= start_char:\n","                    idx += 1\n","                start_positions.append(idx - 1)\n","\n","                idx = context_end\n","                while idx >= context_start and offset[idx][1] >= end_char:\n","                    idx -= 1\n","                end_positions.append(idx + 1)\n","                if i == 2:\n","                    print(start_positions, end_positions)\n","                break\n","        \n","        if len(start_positions) == i:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","    \n","        if i == 774:\n","            print(start_positions, end_positions)\n","\n","    tokenized[\"start_positions\"] = start_positions\n","    tokenized[\"end_positions\"] = end_positions\n","    \n","    return tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["0bdad832cd3b46a39775bb838c3d9749","8b83379394e94e80b659269652903a04","7fe8780cf7b74620b3b1e8cd14f55fd4","8895a76eff08415baf78d76051e60acf","ffe2ee0008744f38b8a3071d665f77a6","008347e162044d5a808a5e66b139c4ad","cdb9f3cc7bf44f1db7d2973de5cf3544","abe691427f934f4194c64eef9b10e368","8836060178b64d56bf1b8bee88e63acb","ff5fcdd2e77d4eecb543134fe5fe6263","0422e8b3bf224d3fa84cb6771430ec6b","5f7c93bacf7a48659bd607024b4b66c4","17c4572835494bf699d4fc8694793c26","ae66991bca4c475788b9b72fa74ebf5f","9ed95030073d4db9a66e4f8bfabc0a58","5af69b30649546aab8e190b1252684b4","c2a6ded8e2ef4cce912f10e831bd5940","cd0d945467fb4fd2a522e747f21a7c99","ab755c51a93e4c049a179ad43208f040","f590dd46ad0a431f95148dc8bb7df059","3ee9b8357b0b4830971724454cb8463c","eaf568c9e31446ecb8acb5853c8f833a","ff051b38dd514f3aaba6d9570b09523d","4d78760595ff4c55b3c2ac87c1cd300b","e93171f7223c4e2697e72e9e8bb0559c","ad2b93acfa494c26abf11baa8cc1dd4c","ae16f195729345119158ca11ef0f2a5f","df5123e984de4beea445e87643fb1d43","883c131010014d51b961aee0c9d9155e","153e30f56e5545829fc9ab0c189fd5fe","d5ee0c4e222c49b58a6898906edcf207","1546f06cfa51481fb2b40211a26c15ed","a056626027c04e0d87207cb7171e2d83"]},"executionInfo":{"elapsed":8905,"status":"ok","timestamp":1653872775139,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"v47JnQbOK6ok","outputId":"dc53de3c-d346-428a-ff89-54c5636f09e9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/498 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bdad832cd3b46a39775bb838c3d9749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7c93bacf7a48659bd607024b4b66c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff051b38dd514f3aaba6d9570b09523d"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"deepakvk/xlnet-base-cased-squad2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4656,"status":"ok","timestamp":1653872781265,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"YXbPOrXaMYjA","outputId":"b59b83c2-4cb5-43dd-b21d-87563d2cd72f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 319] [0, 0, 329]\n","[(4000, 4013)] 8 509 121 0 2138\n","[0, 0, 319, 0, 0, 115, 0, 0, 0, 204, 0, 0, 0, 0, 509, 135, 0, 0, 0, 0, 0, 0, 324, 40, 0, 0, 0, 0, 0, 0, 0, 0, 436, 61, 0, 0, 423, 59, 0, 0, 0, 0, 0, 489, 116, 0, 0, 0, 232, 0, 0, 0, 491, 120, 0, 0, 0, 0, 288, 0, 0, 498, 124, 0, 0, 0, 171, 0, 0, 0, 457, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 407, 38, 0, 0, 0, 429, 59, 0, 0, 266, 0, 0, 122, 0, 0, 0, 0, 0, 308, 41, 0, 0, 0, 0, 292, 0, 0, 0, 0, 0, 151, 0, 0, 0, 464, 90, 0, 0, 0, 359, 0, 0, 0, 476, 215, 0, 0, 0, 0, 179, 0, 0, 0, 335, 0, 0, 0, 0, 0, 161, 0, 0, 0, 0, 165, 0, 0, 0, 0, 337, 0, 0, 0, 0, 439, 65, 0, 0, 0, 499, 125, 0, 353, 0, 184, 35, 0, 0, 0, 0, 485, 111, 0, 0, 0, 0, 209, 0, 0, 0, 0, 482, 110, 0, 0, 0, 0, 347, 0, 0, 0, 0, 198, 0, 0, 0, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 143, 0, 0, 0, 223, 0, 0, 0, 199, 0, 0, 0, 0, 0, 0, 0, 0, 0, 212, 0, 0, 0, 0, 472, 98, 0, 0, 0, 0, 312, 20, 0, 0, 0, 0, 286, 14, 0, 0, 0, 0, 186, 0, 0, 0, 0, 0, 137, 77, 0, 0, 0, 0, 0, 0, 0, 0, 0, 187, 0, 0, 0, 0, 376, 0, 0, 0, 0, 0, 0, 145, 0, 0, 0, 0, 217, 0, 0, 0, 0, 191, 0, 0, 0, 0, 504, 133, 0, 0, 0, 266, 0, 364, 13, 0, 0, 0, 0, 328, 26, 0, 0, 0, 0, 373, 0, 0, 0, 0, 0, 285, 0, 0, 0, 0, 0, 241, 0, 0, 0, 0, 331, 0, 0, 0, 0, 0, 69, 0, 0, 0, 0, 0, 0, 389, 323, 338, 33, 0, 0, 0, 0, 141, 104, 0, 0, 0, 0, 145, 0, 0, 0, 0, 224, 90, 0, 0, 0, 0, 260, 0, 0, 0, 0, 0, 172, 0, 0, 0, 300, 0, 254, 0, 0, 0, 392, 19, 0, 0, 0, 0, 0, 187, 0, 0, 150, 0, 0, 296, 0, 0, 0, 0, 0, 0, 0, 164, 191, 0, 0, 0, 0, 231, 0, 428, 52, 0, 0, 0, 498, 126, 0, 0, 0, 358, 0, 0, 0, 0, 0, 207, 0, 0, 0, 0, 295, 65, 0, 0, 0, 482, 110, 0, 0, 0, 0, 274, 0, 0, 0, 456, 80, 0, 0, 0, 0, 329, 0, 0, 0, 0, 0, 503, 131, 0, 0, 0, 0, 0, 477, 103, 0, 0, 0, 0, 0, 201, 277, 0, 0, 0, 0, 0, 0, 0, 0, 0, 260, 0, 0, 0, 445, 69, 0, 0, 232, 0, 0, 0, 0, 0, 245, 0, 0, 0, 0, 0, 0, 463, 89, 0, 0, 0, 467, 93, 0, 0, 0, 0, 301, 208, 282, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, 221, 0, 0, 0, 0, 0, 337, 0, 0, 28, 0, 0, 0, 0, 0, 0, 152, 0, 0, 0, 0, 493, 125, 0, 0, 0, 0, 0, 210, 0, 0, 0, 0, 223, 0, 0, 0, 0, 204, 0, 0, 0, 0, 0, 0, 0, 0, 294, 242, 236, 0, 0, 0, 351, 0, 0, 0, 0, 427, 54, 0, 0, 0, 0, 189, 0, 0, 30, 0, 0, 0, 0, 0, 0, 230, 0, 0, 0, 308, 163, 0, 0, 0, 0, 212, 0, 0, 0, 0, 181, 0, 0, 0, 0, 289, 0, 0, 0, 0, 210, 0, 0, 0, 0, 325, 117, 167, 0, 116, 0, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 171, 0, 0, 0, 0, 0, 0, 0, 0, 410, 36, 0, 0, 0, 396, 25, 0, 0, 0, 0, 183, 0, 0, 0, 0, 299, 0, 0, 0, 0, 0, 169, 0, 0, 0, 0, 301, 425, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 200, 0, 0, 0, 0, 170, 0, 0, 0, 217, 393, 17, 0, 0, 0, 447, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 142, 0, 0, 0, 0, 240, 0, 0, 0, 0, 0, 0, 0, 506, 137, 0, 0, 0, 0, 179, 499, 472, 0, 0, 153, 166, 0, 258, 0, 0, 455, 79, 0, 0, 0] [0, 0, 329, 0, 0, 116, 0, 0, 0, 208, 0, 0, 0, 0, 510, 136, 0, 0, 0, 0, 0, 0, 325, 42, 0, 0, 0, 0, 0, 0, 0, 0, 440, 65, 0, 0, 510, 183, 0, 0, 0, 0, 0, 490, 117, 0, 0, 0, 232, 0, 0, 0, 497, 126, 0, 0, 0, 0, 290, 0, 0, 500, 126, 0, 0, 0, 186, 0, 0, 0, 458, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 416, 47, 0, 0, 0, 431, 61, 0, 0, 271, 0, 0, 127, 0, 0, 0, 0, 0, 310, 47, 0, 0, 0, 0, 310, 0, 0, 0, 0, 0, 170, 0, 0, 0, 472, 98, 0, 0, 0, 361, 0, 0, 0, 499, 223, 0, 0, 0, 0, 190, 0, 0, 0, 340, 0, 0, 0, 0, 0, 163, 0, 0, 0, 0, 185, 0, 0, 0, 0, 338, 0, 0, 0, 0, 487, 113, 0, 0, 0, 500, 126, 0, 361, 0, 185, 42, 0, 0, 0, 0, 498, 124, 0, 0, 0, 0, 215, 0, 0, 0, 0, 485, 113, 0, 0, 0, 0, 350, 0, 0, 0, 0, 204, 0, 0, 0, 155, 0, 0, 0, 0, 0, 0, 0, 0, 0, 144, 0, 0, 0, 224, 0, 0, 0, 253, 0, 0, 0, 0, 0, 0, 0, 0, 0, 325, 0, 0, 0, 0, 472, 98, 0, 0, 0, 0, 320, 25, 0, 0, 0, 0, 286, 16, 0, 0, 0, 0, 188, 0, 0, 0, 0, 0, 148, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 191, 0, 0, 0, 0, 390, 0, 0, 0, 0, 0, 0, 148, 0, 0, 0, 0, 236, 0, 0, 0, 0, 194, 0, 0, 0, 0, 510, 143, 0, 0, 0, 266, 0, 372, 21, 0, 0, 0, 0, 336, 28, 0, 0, 0, 0, 381, 0, 0, 0, 0, 0, 296, 0, 0, 0, 0, 0, 242, 0, 0, 0, 0, 352, 0, 0, 0, 0, 0, 70, 0, 0, 0, 0, 0, 0, 389, 323, 339, 42, 0, 0, 0, 0, 146, 109, 0, 0, 0, 0, 146, 0, 0, 0, 0, 225, 93, 0, 0, 0, 0, 271, 0, 0, 0, 0, 0, 180, 0, 0, 0, 306, 0, 264, 0, 0, 0, 394, 21, 0, 0, 0, 0, 0, 187, 0, 0, 150, 0, 0, 296, 0, 0, 0, 0, 0, 0, 0, 172, 201, 0, 0, 0, 0, 239, 0, 461, 85, 0, 0, 0, 505, 133, 0, 0, 0, 367, 0, 0, 0, 0, 0, 213, 0, 0, 0, 0, 304, 121, 0, 0, 0, 485, 113, 0, 0, 0, 0, 275, 0, 0, 0, 496, 120, 0, 0, 0, 0, 354, 0, 0, 0, 0, 0, 508, 136, 0, 0, 0, 0, 0, 481, 107, 0, 0, 0, 0, 0, 204, 278, 0, 0, 0, 0, 0, 0, 0, 0, 0, 260, 0, 0, 0, 451, 75, 0, 0, 232, 0, 0, 0, 0, 0, 245, 0, 0, 0, 0, 0, 0, 463, 89, 0, 0, 0, 487, 113, 0, 0, 0, 0, 303, 220, 283, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 228, 0, 0, 0, 0, 0, 346, 0, 0, 28, 0, 0, 0, 0, 0, 0, 167, 0, 0, 0, 0, 498, 130, 0, 0, 0, 0, 0, 228, 0, 0, 0, 0, 243, 0, 0, 0, 0, 207, 0, 0, 0, 0, 0, 0, 0, 0, 318, 263, 263, 0, 0, 0, 362, 0, 0, 0, 0, 438, 65, 0, 0, 0, 0, 203, 0, 0, 59, 0, 0, 0, 0, 0, 0, 238, 0, 0, 0, 312, 167, 0, 0, 0, 0, 214, 0, 0, 0, 0, 193, 0, 0, 0, 0, 293, 0, 0, 0, 0, 216, 0, 0, 0, 0, 393, 133, 193, 0, 119, 0, 0, 0, 0, 0, 0, 161, 0, 0, 0, 0, 234, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 172, 0, 0, 0, 0, 0, 0, 0, 0, 413, 39, 0, 0, 0, 423, 52, 0, 0, 0, 0, 205, 0, 0, 0, 0, 315, 0, 0, 0, 0, 0, 285, 0, 0, 0, 0, 304, 442, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 219, 0, 0, 0, 0, 172, 0, 0, 0, 237, 414, 38, 0, 0, 0, 447, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 149, 0, 0, 0, 0, 282, 0, 0, 0, 0, 0, 0, 0, 510, 141, 0, 0, 0, 0, 203, 510, 484, 0, 0, 159, 200, 0, 264, 0, 0, 463, 87, 0, 0, 0]\n","[0, 468, 95] [0, 468, 95]\n","[(4000, 4014), (4000, 4013), (4607, 4623)] 8 509 128 4622 6651\n","[0, 468, 95, 0, 0, 0, 0, 220, 0, 0, 0, 0, 212, 0, 0, 0, 498, 129, 0, 0, 340, 0, 0, 0, 0, 0, 0, 141, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 297, 0, 0, 0, 0, 482, 107, 0, 0, 213, 0, 0, 0, 0, 0, 205, 64, 0, 0, 0, 0, 449, 77, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 281, 0, 0, 0, 0, 0, 0, 211, 0, 0, 0, 0, 294, 0, 0, 0, 495, 126, 0, 0, 0, 0, 0, 395, 21, 0, 0, 0, 0, 144, 0, 0, 0, 0, 225, 0, 0, 331, 0, 0, 0, 0, 0, 0, 332, 37, 0, 0, 0, 0, 0, 0, 227, 0, 0, 0, 0, 465, 89, 330, 0, 0, 0, 0, 0, 490, 115, 0, 0, 501, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 493, 118, 0, 0, 482, 115, 0, 0, 0, 0, 235, 0, 0, 0, 0, 0, 302, 0, 0, 0, 262, 0, 352, 74, 0, 0, 0, 0, 0, 0, 372, 70, 0, 0, 0, 0, 159, 0, 0, 0, 487, 114, 0, 0, 0, 0, 0, 0, 0, 0, 0, 277, 0, 0, 0, 0, 397, 452, 81, 0, 0, 0, 497, 123, 0, 0, 0, 0, 0, 0, 140, 0, 0, 0, 0, 504, 129, 0, 0, 0, 298, 69, 0, 0, 0, 467, 92, 0, 0, 509, 139, 0, 0, 0, 0, 0, 241, 0, 0, 0, 0, 252, 0, 0, 0, 0, 500, 128, 0, 0, 0, 222, 0, 0, 252, 0, 0, 0, 0, 0, 155, 0, 0, 0, 489, 117, 0, 0, 0, 0, 210, 0, 0, 0, 0, 0, 297, 0, 0, 0, 0, 0, 267, 0, 0, 0, 0, 463, 88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 227, 0, 0, 0, 0, 146, 0, 0, 0, 0, 0, 329, 0, 0, 0, 0, 0, 170, 0, 0, 487, 114, 0, 0, 0, 0, 215, 0, 0, 0, 0, 266, 0, 0, 0, 0, 0, 0, 0, 199, 0, 0, 0, 0, 0, 239, 496, 126, 0, 0, 0, 0, 286, 0, 0, 0, 33, 0, 0, 0, 0, 0, 182, 0, 0, 0, 0, 0, 239, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 225, 203, 0, 0, 0, 0, 0, 0, 0, 0, 0, 389, 17, 0, 0, 0, 351, 0, 0, 0, 0, 497, 126, 0, 0, 0, 484, 113, 0, 0, 0, 178, 0, 459, 502, 129, 0, 0, 0, 0, 0, 256, 0, 0, 0, 492, 120, 0, 0, 0, 0, 219, 21, 0, 0, 0, 0, 226, 0, 178, 0, 0, 0, 0, 210, 0, 0, 0, 0, 154, 0, 0, 0, 136, 0, 0, 0, 0, 0, 188, 319, 0, 0, 166, 0, 0, 0, 0, 166, 0, 0, 0, 0, 0, 203, 0, 491, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 140, 179, 0, 0, 0, 0, 0, 304, 0, 0, 0, 0, 440, 65, 0, 0, 0, 425, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 184, 0, 264, 0, 0, 0, 238, 0, 0, 0, 0, 0, 237, 0, 0, 0, 0, 0, 0, 0, 0, 0, 208, 0, 0, 0, 245, 0, 0, 178, 0, 0, 0, 0, 0, 0, 274, 0, 0, 0, 0, 0, 342, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 427, 54, 0, 0, 0, 0, 148, 0, 0, 0, 0, 501, 127, 8, 0, 0, 0, 0, 206, 0, 0, 0, 0, 0, 0, 0, 0, 0, 341, 0, 0, 0, 323, 0, 0, 0, 0, 155, 0, 0, 0, 0, 231, 0, 0, 175, 0, 0, 0, 0, 0, 292, 14, 0, 0, 0, 0, 0, 0, 0, 0, 509, 142, 0, 0, 0, 165, 0, 0, 0, 0, 0, 386, 0, 459, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 171, 0, 0, 0, 0, 0, 171, 0, 0, 0, 0, 232, 0, 0, 0, 0, 248, 33, 0, 0, 0, 509, 137, 0, 0, 0, 0, 329, 40, 0, 0, 0, 0, 198, 0, 0, 495, 122, 0, 0, 0, 452, 81, 0, 0, 0, 493, 121, 0, 0, 0, 0, 158, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 178, 0, 0, 0, 454, 83, 0, 0, 0, 0, 176, 0, 0, 0, 205, 0, 0, 0, 0, 162, 0, 0, 0, 0, 304, 0, 0, 0, 0, 0, 0, 355, 0, 0, 0, 0, 412, 38, 0, 0, 0, 252, 0] [0, 468, 95, 0, 0, 0, 0, 233, 0, 0, 0, 0, 213, 0, 0, 0, 500, 131, 0, 0, 352, 0, 0, 0, 0, 0, 0, 169, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 307, 0, 0, 0, 0, 495, 120, 0, 0, 213, 0, 0, 0, 0, 0, 214, 69, 0, 0, 0, 0, 451, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 290, 0, 0, 0, 0, 0, 0, 217, 0, 0, 0, 0, 295, 0, 0, 0, 509, 140, 0, 0, 0, 0, 0, 399, 25, 0, 0, 0, 0, 151, 0, 0, 0, 0, 233, 0, 0, 335, 0, 0, 0, 0, 0, 0, 356, 54, 0, 0, 0, 0, 0, 0, 230, 0, 0, 0, 0, 510, 141, 372, 0, 0, 0, 0, 0, 495, 120, 0, 0, 510, 155, 0, 0, 0, 0, 0, 0, 0, 0, 0, 500, 125, 0, 0, 492, 125, 0, 0, 0, 0, 253, 0, 0, 0, 0, 0, 306, 0, 0, 0, 263, 0, 354, 76, 0, 0, 0, 0, 0, 0, 373, 72, 0, 0, 0, 0, 231, 0, 0, 0, 510, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 277, 0, 0, 0, 0, 399, 468, 97, 0, 0, 0, 503, 129, 0, 0, 0, 0, 0, 0, 143, 0, 0, 0, 0, 506, 131, 0, 0, 0, 308, 72, 0, 0, 0, 478, 103, 0, 0, 510, 211, 0, 0, 0, 0, 0, 301, 0, 0, 0, 0, 255, 0, 0, 0, 0, 507, 135, 0, 0, 0, 222, 0, 0, 253, 0, 0, 0, 0, 0, 166, 0, 0, 0, 491, 119, 0, 0, 0, 0, 302, 0, 0, 0, 0, 0, 334, 0, 0, 0, 0, 0, 276, 0, 0, 0, 0, 486, 111, 0, 0, 0, 0, 0, 0, 0, 0, 0, 234, 0, 0, 0, 0, 159, 0, 0, 0, 0, 0, 340, 0, 0, 0, 0, 0, 176, 0, 0, 488, 115, 0, 0, 0, 0, 232, 0, 0, 0, 0, 270, 0, 0, 0, 0, 0, 0, 0, 211, 0, 0, 0, 0, 0, 240, 497, 127, 0, 0, 0, 0, 292, 0, 0, 0, 159, 0, 0, 0, 0, 0, 196, 0, 0, 0, 0, 0, 256, 123, 0, 0, 0, 0, 0, 0, 0, 0, 0, 229, 205, 0, 0, 0, 0, 0, 0, 0, 0, 0, 389, 17, 0, 0, 0, 352, 0, 0, 0, 0, 499, 128, 0, 0, 0, 488, 117, 0, 0, 0, 185, 0, 461, 510, 143, 0, 0, 0, 0, 0, 258, 0, 0, 0, 498, 126, 0, 0, 0, 0, 230, 27, 0, 0, 0, 0, 229, 0, 182, 0, 0, 0, 0, 212, 0, 0, 0, 0, 192, 0, 0, 0, 138, 0, 0, 0, 0, 0, 193, 322, 0, 0, 207, 0, 0, 0, 0, 169, 0, 0, 0, 0, 0, 203, 0, 510, 164, 0, 0, 0, 0, 0, 0, 0, 0, 0, 140, 186, 0, 0, 0, 0, 0, 332, 0, 0, 0, 0, 475, 100, 0, 0, 0, 427, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 189, 0, 277, 0, 0, 0, 256, 0, 0, 0, 0, 0, 254, 0, 0, 0, 0, 0, 0, 0, 0, 0, 235, 0, 0, 0, 255, 0, 0, 187, 0, 0, 0, 0, 0, 0, 284, 0, 0, 0, 0, 0, 355, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 432, 59, 0, 0, 0, 0, 149, 0, 0, 0, 0, 504, 130, 9, 0, 0, 0, 0, 208, 0, 0, 0, 0, 0, 0, 0, 0, 0, 343, 0, 0, 0, 324, 0, 0, 0, 0, 164, 0, 0, 0, 0, 324, 0, 0, 175, 0, 0, 0, 0, 0, 299, 23, 0, 0, 0, 0, 0, 0, 0, 0, 510, 142, 0, 0, 0, 189, 0, 0, 0, 0, 0, 413, 0, 460, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, 182, 0, 0, 0, 0, 237, 0, 0, 0, 0, 252, 42, 0, 0, 0, 510, 186, 0, 0, 0, 0, 343, 58, 0, 0, 0, 0, 220, 0, 0, 506, 133, 0, 0, 0, 452, 81, 0, 0, 0, 510, 141, 0, 0, 0, 0, 179, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 196, 0, 0, 0, 454, 83, 0, 0, 0, 0, 197, 0, 0, 0, 226, 0, 0, 0, 0, 167, 0, 0, 0, 0, 327, 0, 0, 0, 0, 0, 0, 364, 0, 0, 0, 0, 412, 38, 0, 0, 0, 257, 0]\n","[0, 0, 248] [0, 0, 251]\n","[(27139, 27230), (27735, 27913), (27931, 28130), (4000, 4150), (27103, 27232), (27562, 27914)] 27 509 123 4955 7286\n","[0, 0, 248, 0, 0, 25, 0, 0, 0, 0, 0, 398, 26, 0, 0, 0, 239, 0, 0, 0, 325, 367, 454, 81, 0, 0, 426, 53, 0, 0, 0, 0, 0, 0, 0, 258, 0, 0, 0, 0, 490, 115, 0, 0, 0, 461, 88, 0, 0, 0, 0, 168, 0, 0, 0, 0, 0, 0, 0, 0, 349, 24, 0, 0, 0, 271, 301, 0, 0, 0, 0, 285, 0, 0, 0, 0, 260, 0, 0, 0, 0, 0, 407, 46, 0, 0, 480, 109, 0, 0, 0, 125, 0, 0, 0, 0, 0, 503, 128, 0, 0, 0, 178, 284, 14, 0, 0, 410, 37, 18, 0, 0, 0, 460, 88, 0, 0, 0, 0, 188, 0, 0, 9, 0, 0, 0, 0, 0, 0, 357, 0, 0, 0, 334, 0, 259, 0, 0, 0, 0, 204, 0, 0, 21, 0, 0, 0, 0, 0, 0, 393, 18, 0, 0, 323, 0, 0, 0, 219, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 388, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 185, 0, 0, 0, 0, 0, 0, 0, 0, 364, 30, 0, 0, 0, 344, 0, 0, 0, 366, 0, 0, 0, 0, 387, 13, 0, 0, 0, 0, 352, 0, 193, 0, 0, 0, 0, 156, 0, 0, 0, 0, 460, 168, 0, 0, 0, 0, 181, 0, 0, 0, 191, 0, 0, 0, 0, 0, 0, 0, 212, 0, 0, 0, 0, 0, 145, 0, 303, 0, 0, 381, 0, 0, 0, 458, 85, 0, 0, 0, 0, 203, 321, 0, 0, 0, 0, 397, 355, 29, 0, 0, 0, 0, 382, 11, 0, 0, 0, 470, 96, 0, 0, 0, 437, 63, 0, 0, 214, 0, 0, 0, 0, 0, 0, 240, 0, 0, 0, 466, 90, 0, 0, 0, 0, 478, 106, 0, 0, 0, 0, 200, 207, 424, 51, 39, 164, 162, 257, 0, 0, 0, 0, 0, 219, 0, 0, 0, 414, 39, 0, 0, 0, 459, 86, 0, 0, 0, 0, 0, 359, 37, 0, 0, 0, 0, 242, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 185, 0, 0, 0, 0, 0, 0, 0, 464, 96, 0, 0, 0, 0, 297, 0, 0, 0, 0, 0, 0, 0, 204, 0, 0, 0, 0, 0, 0, 0, 459, 86, 0, 0, 0, 304, 158, 0, 0, 0, 0, 0, 147, 0, 0, 0, 0, 0, 0, 0, 0, 125, 0, 0, 0, 254, 0, 0, 0, 298, 0, 0, 0, 0, 0, 350, 45, 0, 0, 0, 0, 0, 190, 0, 0, 238, 203, 221, 166, 35, 0, 0, 135, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 236, 0, 0, 272, 0, 0, 0, 0, 0, 0, 0, 0, 0, 213, 0, 0, 0, 467, 95, 0, 0, 0, 0, 292, 0, 0, 0, 0, 377, 0, 0, 0, 0, 0, 265, 0, 0, 0, 0, 285, 0, 0, 0, 0, 252, 0, 0, 0, 0, 0, 198, 0, 0, 421, 47, 438, 64, 0, 0, 87, 0, 0, 0, 0, 0, 0, 0, 298, 0, 0, 0, 80, 0, 0, 0, 0, 0, 0, 271, 0, 0, 0, 0, 0, 0, 0, 478, 105, 0, 0, 0, 0, 302, 0, 0, 0, 0, 170, 0, 0, 0, 0, 329, 17, 0, 0, 0, 0, 238, 0, 0, 0, 504, 135, 0, 0, 0, 0, 160, 0, 0, 0, 464, 92, 0, 0, 0, 0, 0, 0, 263, 0, 165, 0, 0, 0, 0, 242, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 325, 0, 0, 0, 0, 0, 191, 202, 344, 0, 0, 0, 0, 148, 0, 0, 0, 399, 142, 0, 0, 0, 0, 349, 137, 0, 0, 0, 480, 108, 0, 300, 0, 0, 0, 0, 484, 111, 0, 0, 0, 0, 0, 215, 490, 117, 0, 0, 0, 472, 98, 0, 0, 245, 0, 0, 437, 70, 0, 0, 0, 0, 178, 428, 54, 0, 0, 0, 0, 346, 0, 0, 0, 0, 0, 309, 58, 0, 0, 0, 0, 231, 0, 446, 78, 0, 0, 0, 0, 214, 0, 0, 0, 451, 163, 111, 0, 0, 360, 0, 0, 0, 0, 0, 475, 103, 0, 0, 0, 148, 0, 141, 0, 0, 0, 0, 158, 0, 0, 0, 0, 0, 0, 383, 11, 0, 0, 0, 417, 46, 0, 0, 0, 199, 0, 0, 0, 0, 0, 179, 0, 0, 0, 167, 0, 0, 0, 0, 148, 0, 0, 0, 0, 472, 105, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 161, 0] [0, 0, 251, 0, 0, 25, 0, 0, 0, 0, 0, 408, 36, 0, 0, 0, 252, 0, 0, 0, 328, 372, 456, 83, 0, 0, 426, 53, 0, 0, 0, 0, 0, 0, 0, 260, 0, 0, 0, 0, 498, 123, 0, 0, 0, 461, 88, 0, 0, 0, 0, 167, 0, 0, 0, 0, 0, 0, 0, 0, 355, 26, 0, 0, 0, 276, 303, 0, 0, 0, 0, 308, 0, 0, 0, 0, 260, 0, 0, 0, 0, 0, 414, 53, 0, 0, 481, 110, 0, 0, 0, 140, 0, 0, 0, 0, 0, 510, 141, 0, 0, 0, 187, 286, 22, 0, 0, 431, 58, 53, 0, 0, 0, 483, 111, 0, 0, 0, 0, 249, 0, 0, 63, 0, 0, 0, 0, 0, 0, 370, 0, 0, 0, 334, 0, 259, 0, 0, 0, 0, 230, 0, 0, 21, 0, 0, 0, 0, 0, 0, 401, 26, 0, 0, 329, 0, 0, 0, 221, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 391, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 185, 0, 0, 0, 0, 0, 0, 0, 0, 368, 31, 0, 0, 0, 346, 0, 0, 0, 369, 0, 0, 0, 0, 388, 14, 0, 0, 0, 0, 355, 0, 201, 0, 0, 0, 0, 170, 0, 0, 0, 0, 461, 171, 0, 0, 0, 0, 183, 0, 0, 0, 202, 0, 0, 0, 0, 0, 0, 0, 222, 0, 0, 0, 0, 0, 157, 0, 304, 0, 0, 381, 0, 0, 0, 459, 86, 0, 0, 0, 0, 204, 321, 0, 0, 0, 0, 401, 357, 41, 0, 0, 0, 0, 411, 40, 0, 0, 0, 477, 103, 0, 0, 0, 445, 71, 0, 0, 262, 0, 0, 0, 0, 0, 0, 245, 0, 0, 0, 468, 92, 0, 0, 0, 0, 486, 114, 0, 0, 0, 0, 201, 217, 431, 58, 49, 176, 182, 320, 0, 0, 0, 0, 0, 224, 0, 0, 0, 429, 54, 0, 0, 0, 460, 87, 0, 0, 0, 0, 0, 362, 43, 0, 0, 0, 0, 246, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 196, 0, 0, 0, 0, 0, 0, 0, 492, 124, 0, 0, 0, 0, 323, 0, 0, 0, 0, 0, 0, 0, 207, 0, 0, 0, 0, 0, 0, 0, 464, 91, 0, 0, 0, 308, 174, 0, 0, 0, 0, 0, 157, 0, 0, 0, 0, 0, 0, 0, 0, 127, 0, 0, 0, 256, 0, 0, 0, 299, 0, 0, 0, 0, 0, 350, 47, 0, 0, 0, 0, 0, 192, 0, 0, 241, 205, 228, 167, 36, 0, 0, 137, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 236, 0, 0, 274, 0, 0, 0, 0, 0, 0, 0, 0, 0, 278, 0, 0, 0, 468, 96, 0, 0, 0, 0, 303, 0, 0, 0, 0, 379, 0, 0, 0, 0, 0, 289, 0, 0, 0, 0, 294, 0, 0, 0, 0, 290, 0, 0, 0, 0, 0, 214, 0, 0, 425, 51, 445, 71, 0, 0, 88, 0, 0, 0, 0, 0, 0, 0, 319, 0, 0, 0, 125, 0, 0, 0, 0, 0, 0, 275, 0, 0, 0, 0, 0, 0, 0, 510, 142, 0, 0, 0, 0, 319, 0, 0, 0, 0, 182, 0, 0, 0, 0, 348, 37, 0, 0, 0, 0, 240, 0, 0, 0, 510, 171, 0, 0, 0, 0, 163, 0, 0, 0, 468, 96, 0, 0, 0, 0, 0, 0, 269, 0, 170, 0, 0, 0, 0, 283, 0, 0, 0, 0, 216, 0, 0, 0, 0, 0, 0, 0, 0, 0, 339, 0, 0, 0, 0, 0, 195, 206, 345, 0, 0, 0, 0, 161, 0, 0, 0, 401, 145, 0, 0, 0, 0, 352, 140, 0, 0, 0, 510, 166, 0, 301, 0, 0, 0, 0, 485, 112, 0, 0, 0, 0, 0, 215, 498, 125, 0, 0, 0, 472, 98, 0, 0, 246, 0, 0, 438, 71, 0, 0, 0, 0, 202, 432, 58, 0, 0, 0, 0, 346, 0, 0, 0, 0, 0, 315, 68, 0, 0, 0, 0, 233, 0, 451, 83, 0, 0, 0, 0, 214, 0, 0, 0, 452, 165, 114, 0, 0, 373, 0, 0, 0, 0, 0, 479, 107, 0, 0, 0, 150, 0, 142, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 392, 20, 0, 0, 0, 420, 49, 0, 0, 0, 200, 0, 0, 0, 0, 0, 194, 0, 0, 0, 181, 0, 0, 0, 0, 158, 0, 0, 0, 0, 506, 139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 191, 0]\n"]}],"source":["MAX_LEN = 512\n","stride = 128\n","\n","data_preprocessing_pipeline = lambda df: preprocess_data(df, tokenizer, MAX_LEN, stride)\n","\n","df_train_tokenized = data_preprocessing_pipeline(df_train)\n","df_val_tokenized = data_preprocessing_pipeline(df_val)\n","df_test_tokenized = data_preprocessing_pipeline(df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Keu6AN65RX0"},"outputs":[],"source":["class TextDataset(Dataset):\n","  def __init__(self, questions, starts, ends, attention_masks, df_index, offset_mapping):\n","    self.questions = questions\n","    self.starts = starts\n","    self.ends = ends\n","    self.attention_masks = attention_masks\n","    self.df_index = df_index\n","    self.offset_mapping = offset_mapping\n","\n","  def __len__(self):\n","    return len(self.questions)\n","\n","  def __getitem__(self, item):\n","    question = self.questions[item]\n","    attention_mask = self.attention_masks[item]\n","    start = self.starts[item]\n","    end = self.ends[item]\n","    df_index = self.df_index[item]\n","    offset_mapping = self.offset_mapping[item]\n","\n","\n","    return {\n","      'input_ids': torch.tensor(question, dtype = torch.long),\n","      'attention_mask': torch.tensor(attention_mask, dtype = torch.long),\n","      'start_positions': torch.tensor(start, dtype=torch.long),\n","      'end_positions' : torch.tensor(end, dtype = torch.long),\n","      'df_index': torch.tensor(df_index, dtype=torch.long),\n","      'offset_mapping': offset_mapping\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOioYhl3HD8A"},"outputs":[],"source":["train_dataset = TextDataset(\n","    questions = df_train_tokenized['input_ids'],\n","    starts = df_train_tokenized['start_positions'],\n","    ends = df_train_tokenized['end_positions'],\n","    attention_masks = df_train_tokenized['attention_mask'],\n","    df_index = df_train_tokenized[\"overflow_to_sample_mapping\"],\n","    offset_mapping = df_train_tokenized[\"offset_mapping\"]\n",")\n","\n","val_dataset = TextDataset(\n","    questions = df_val_tokenized['input_ids'],\n","    starts = df_val_tokenized['start_positions'],\n","    ends = df_val_tokenized['end_positions'],\n","    attention_masks = df_val_tokenized['attention_mask'],\n","    df_index = df_val_tokenized[\"overflow_to_sample_mapping\"],\n","    offset_mapping = df_val_tokenized[\"offset_mapping\"]\n",")\n","\n","test_dataset = TextDataset(\n","    questions = df_test_tokenized['input_ids'],\n","    starts = df_test_tokenized['start_positions'],\n","    ends = df_test_tokenized['end_positions'],\n","    attention_masks = df_test_tokenized['attention_mask'],\n","    df_index = df_test_tokenized[\"overflow_to_sample_mapping\"],\n","    offset_mapping = df_test_tokenized[\"offset_mapping\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRyz7LkCpOen"},"outputs":[],"source":["batch_size = 8\n","\n","\n","# train_sampler = RandomSampler(train_data)\n","# val_sampler = RandomSampler(val_data)\n","# test_sampler = RandomSampler(test_data)\n","\n","# train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n","# val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n","# test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dowik7NKr89L"},"outputs":[],"source":["import gc\n","gc.collect()\n","import torch\n","torch.cuda.empty_cache()\n","import random\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)\n","\n","SEED = 19\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if device == torch.device(\"cuda\"):\n","    torch.cuda.manual_seed_all(SEED)\n","\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["c74b1339eeea4ae8a62625d6ba70c493","631f7eed276a41fe8c97b03e8a9496c1","811343954b704a9495d005326e2ede07","5c23da1e53cd4225bcc77ecf68f3804f","ffa2bbde638b4462ae71a170b5b4b0ce","36e6547177b045628f11bc5c3f9b0f9c","3aa48a26cbc140a29b18553bf5606675","b812f1750d1c4d418b2a91aa43a92737","c325b86b60ea4d59baddb8eb378f295d","e3db8043a7864cd3a661453a90b4120b","2e18963d8d6a452384ef40c450701ed1","dd9cbb461c0e4842b8d825b6b94c12d4","08e647255197495b927e5ba78ab8f130","aa4d0ec6f86a4d6db5968832ed7e9748","b5df0e7f5ece4003bc79ef5a93a35367","191af0232e4e488a932e95739f2eda08","296daf131c25433682bf3efa165b8ba9","d1624524764d4962bf1153fcbcef328f","ade3c3ae6412476e97a09cf4dc11e23d","82f2d6a4f98a47c88d1bb4716709628a","28e91547633148068a97481551d86027","f33a03d30c7d49a08e7c72fb1453ccb1"]},"executionInfo":{"elapsed":27180,"status":"ok","timestamp":1653872822604,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"Ijuz53S3ugwq","outputId":"8aa3177b-76cf-4859-a01a-697d4f140ed9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/945 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c74b1339eeea4ae8a62625d6ba70c493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd9cbb461c0e4842b8d825b6b94c12d4"}},"metadata":{}}],"source":["from transformers import TrainingArguments, Trainer\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"deepakvk/xlnet-base-cased-squad2\").to(device)\n","model_checkpoint = \"deepakvk/xlnet-base-cased-squad2\"\n","\n","model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    output_dir = \"/content/drive/MyDrive/SEW.NLP/logs/xlnet_7\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_dir = \"./logs/runs\",\n","    do_train = True,\n","    do_eval = True,\n","    learning_rate=5e-5, # best 5e-5\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_accumulation_steps=6, # best 6\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    logging_steps = 25\n","\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"guDJ_GU8v1IR"},"outputs":[],"source":["from transformers import default_data_collator\n","\n","data_collator = default_data_collator\n","\n","\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= val_dataset,\n","    data_collator=data_collator\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":866},"executionInfo":{"elapsed":1783444,"status":"ok","timestamp":1653859208772,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"lEle2e9gyZEx","outputId":"d3b65b48-c0e1-470b-9718-8b4a714d0c2a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 6281\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 294\n","The following columns in the training set don't have a corresponding argument in `XLNetForQuestionAnsweringSimple.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `XLNetForQuestionAnsweringSimple.forward`,  you can safely ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [294/294 29:37, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.333200</td>\n","      <td>1.099816</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.913500</td>\n","      <td>1.070145</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.669200</td>\n","      <td>1.206309</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 777\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `XLNetForQuestionAnsweringSimple.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `XLNetForQuestionAnsweringSimple.forward`,  you can safely ignore this message.\n","Saving model checkpoint to /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-98\n","Configuration saved in /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-98/config.json\n","Model weights saved in /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-98/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 777\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `XLNetForQuestionAnsweringSimple.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `XLNetForQuestionAnsweringSimple.forward`,  you can safely ignore this message.\n","Saving model checkpoint to /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-196\n","Configuration saved in /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-196/config.json\n","Model weights saved in /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-196/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 777\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `XLNetForQuestionAnsweringSimple.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `XLNetForQuestionAnsweringSimple.forward`,  you can safely ignore this message.\n","Saving model checkpoint to /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-294\n","Configuration saved in /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-294/config.json\n","Model weights saved in /content/drive/MyDrive/SEW.NLP/logs/xlnet_7/checkpoint-294/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 26min 56s, sys: 3min 35s, total: 30min 32s\n","Wall time: 29min 43s\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=294, training_loss=1.1638301635275081, metrics={'train_runtime': 1783.1615, 'train_samples_per_second': 10.567, 'train_steps_per_second': 0.165, 'total_flos': 5331264684797952.0, 'train_loss': 1.1638301635275081, 'epoch': 3.0})"]},"metadata":{},"execution_count":45}],"source":["%%time\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ea8e5Zpb_BiO"},"outputs":[],"source":["# current best \"/content/drive/MyDrive/SEW.NLP/logs/xlnet_6/checkpoint-262\"\n","\n","PATH_MODEL = \"/content/drive/MyDrive/SEW.NLP/logs/xlnet_6/checkpoint-262\" # path of model saved at best epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7c30AOAeG0Ut"},"outputs":[],"source":["best_model = AutoModelForQuestionAnswering.from_pretrained(PATH_MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"elapsed":30765,"status":"ok","timestamp":1653872853359,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"Vhr8SXNYIb1y","outputId":"dadb15a5-f07b-4454-9661-d68a16250871"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 777\n","  Batch size = 8\n","The following columns in the test set don't have a corresponding argument in `XLNetForQuestionAnsweringSimple.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `XLNetForQuestionAnsweringSimple.forward`,  you can safely ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [98/98 00:30]\n","    </div>\n","    "]},"metadata":{}}],"source":["best_trainer = Trainer(\n","    best_model,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= test_dataset,\n","    data_collator=data_collator\n",")\n","\n","val_predictions = best_trainer.predict(val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNZQhrfus1Ck"},"outputs":[],"source":["df_train_tokenized[0].tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-POH0MvhqyG"},"outputs":[],"source":["def compute_best_prediction(start_indexes, end_indexes,\n","                            start_logits, end_logits,\n","                            sequence_ids, offset_mapping, context):\n","    \"\"\"\n","      Computes best feasible prediction and compares it with null prediction\n","    \"\"\"\n","\n","\n","    best_score, null_score = -np.inf, -np.inf\n","    best_answer = \"\"\n","    best_start, best_end = 0, 0\n","\n","    \n","    for start_index in start_indexes:\n","        for end_index in end_indexes:\n","            score = start_logits[start_index] + end_logits[end_index]\n","            if start_index == 0 or end_index == 0: # null prediction\n","                if start_index != end_index:\n","                    continue\n","                null_score = score\n","            \n","            elif start_index <= end_index and sequence_ids[start_index] == 1 and sequence_ids[end_index] == 1 and start_index != 510 and end_index != 510:\n","                if score > best_score:\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    if end_char > 0:\n","                        best_answer = context[start_char:end_char]\n","                        best_score = score\n","                        best_start = start_index\n","                        best_end = end_index\n","    \n","    score_diff = null_score - best_score\n","    \n","\n","    return {\n","        \"score_diff\": score_diff,\n","        \"pred_start\": best_start,\n","        \"pred_end\": best_end,\n","        \"pred_answer\": best_answer\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnfXJYoYmFDg"},"outputs":[],"source":["def get_preds_df(predictions, df, tokenized_df, dataset):\n","    predicted_answers = []\n","    n_best_size = 20\n","\n","    test_start_logits, test_end_logits = predictions.predictions\n","    start_labels, end_labels = tokenized_df[\"start_positions\"], tokenized_df[\"end_positions\"]\n","\n","    for i in range(len(dataset)):\n","\n","        start_label, end_label = start_labels[i], end_labels[i]\n","        start_logits, end_logits = test_start_logits[i], test_end_logits[i]\n","\n","        start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","        end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","\n","        row_idx = dataset[i][\"df_index\"].item()\n","        row_context = df.loc[row_idx, \"narrowed_context\"]\n","        offset_mapping = dataset[i][\"offset_mapping\"]\n","        sequence_ids = tokenized_df.token_type_ids[i]\n","        \n","        # find predicted answer:\n","        prediction = compute_best_prediction(start_indexes, end_indexes, start_logits, end_logits, sequence_ids, offset_mapping, row_context)\n","        \n","        # find correct answer:\n","        start_char_true = offset_mapping[start_label][0]\n","        end_char_true = offset_mapping[end_label][1]\n","        correct_answer = row_context[start_char_true:end_char_true+1] if end_label > 0 else \"\"\n","        \n","        prediction[\"pred_token\"] = tokenized_df[i].tokens[prediction[\"pred_start\"]:prediction[\"pred_end\"]+1]\n","        prediction[\"start_label\"] = start_label\n","        prediction[\"end_label\"] = end_label\n","        prediction[\"correct_answer\"] = correct_answer\n","        prediction[\"correct_token\"] = tokenized_df[i].tokens[start_label:end_label+1] if end_label > 0 else [\"<cls>\"]\n","\n","        predicted_answers.append(prediction)\n","\n","    preds_df = pd.DataFrame(predicted_answers)\n","    preds_df[\"NoAnsw\"] = preds_df.apply(lambda row: row[\"correct_token\"] == [\"<cls>\"], axis=1)\n","    \n","    return preds_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgLJSZ8oD83P"},"outputs":[],"source":["val_preds_df = get_preds_df(val_predictions, df_val, df_val_tokenized, val_dataset)"]},{"cell_type":"code","source":["val_preds_df[val_preds_df[\"correct_answer\"] != \"\"].tail(50)"],"metadata":{"id":"0M7YfO46FLAX","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1653873075523,"user_tz":420,"elapsed":308,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"df0972fb-58e0-4029-8794-95dfefa4058e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     score_diff  pred_start  pred_end  \\\n","549   -1.885360         218       232   \n","553   -3.145474         245       277   \n","556   -2.815018         180       183   \n","563   -6.857100         274       283   \n","569    2.232587         339       367   \n","580   -2.373489         427       435   \n","581   -2.002007          54        62   \n","586   -1.429255         148       149   \n","591    0.754134         266       273   \n","592    0.171875         363       367   \n","593    2.322204         392       394   \n","598    8.065354         144       144   \n","608    0.327970         231       231   \n","612    1.062492         296       300   \n","617   -0.651468         499       500   \n","622   -3.998379         236       246   \n","625   -4.603097         175       176   \n","631   -5.748355         291       299   \n","632    0.049258          38        46   \n","642   -0.137658         142       142   \n","646    5.025795         165       172   \n","652   14.055028         324       379   \n","654    0.555589         459       460   \n","655    1.031443          89        90   \n","666   -2.958414         171       172   \n","672   -7.635859         171       177   \n","677    6.474312         232       237   \n","682   -5.391022         251       252   \n","683   -2.247106          36        38   \n","688   -1.751326         158       186   \n","693    5.133382         259       296   \n","694    2.680057         167       186   \n","699    3.410821         186       220   \n","702   -3.777361         495       507   \n","703   -4.740989         122       134   \n","707    3.400307         452       452   \n","708    1.543939         153       170   \n","713   -4.137244         121       132   \n","718    1.946070         178       180   \n","732   -3.921979         184       189   \n","736    0.881764         454       454   \n","737    0.903186          83        83   \n","742    4.200628          53        62   \n","746   -5.080938         188       191   \n","751   -4.051925         165       168   \n","756   -7.127333         304       308   \n","763   -1.722377         355       378   \n","768    0.550560         412       412   \n","769    2.847054         241       241   \n","773   -3.151261         252       256   \n","\n","                                           pred_answer  \\\n","549  R, RMSE, MSE, bias, and computational time com...   \n","553  bag-of-words (BOW), term frequency–inverse doc...   \n","556                                          Meta-LSTM   \n","563        Daily Mail news articles released by BIBREF   \n","569  three of the large-scale document classificati...   \n","580  Stanford Sentiment Treebank movie reviews dataset   \n","581  Stanford Sentiment Treebank movie reviews dataset   \n","586                                               BLEU   \n","591                   $n$-gram based similarity metric   \n","592                                 n-gram based score   \n","593                         neural machine translation   \n","598                                             90,000   \n","608                                                 17   \n","612               strong retrieval and neural baseline   \n","617                                               BLEU   \n","622  it should be highly correlated with human judg...   \n","625                                                244   \n","631             a real-world chatting corpus from DuMi   \n","632      The dataset was crawled from the Douban forum   \n","642                                            english   \n","646    We also present our dataset for public research   \n","652  These results, in addition to the number of le...   \n","654                                               BLEU   \n","655                                               BLEU   \n","666                                   Content Fidelity   \n","672                       Stanford Plane Crash Dataset   \n","677                                 INLINEFORM0 scores   \n","682                                              Naive   \n","683                                              AuxNN   \n","688  an utd system is applied to the target languag...   \n","693  we follow the Kaldi recipes for the GlobalPhon...   \n","694  we trained a separate i-vector extractor for e...   \n","699  From the results which we get, it is evident t...   \n","702  1000 conversations composed of 6833 sentences ...   \n","703  1000 conversations composed of 6833 sentences ...   \n","707                                                 58   \n","708  58 typically developing children, aged 5-12 ye...   \n","713                90,369,215 tweets written in French   \n","718                                              HexaF   \n","732                             ceccarelli2013learning   \n","736                                            Twitter   \n","737                                            Twitter   \n","742       web-based word association experiment BIBREF   \n","746                                        ROUGE score   \n","751                                              ASKfm   \n","756                                       3,731 movies   \n","763  9 Amazon product review datasets for 9 differe...   \n","768                                            English   \n","769                                            English   \n","773                                      EM INLINEFORM   \n","\n","                                            pred_token  start_label  \\\n","549  [▁R, ,, ▁, RM, SE, ,, ▁M, SE, ,, ▁bias, ,, ▁an...          208   \n","553  [▁bag, -, of, -, word, s, ▁, (, BO, W, ), ,, ▁...          245   \n","556                                 [▁Meta, -, LS, TM]          178   \n","563  [▁Daily, ▁Mail, ▁news, ▁articles, ▁released, ▁...          274   \n","569  [▁three, ▁of, ▁the, ▁large, -, scale, ▁documen...          342   \n","580  [▁Stanford, ▁Sen, ti, ment, ▁Tree, bank, ▁movi...          427   \n","581  [▁Stanford, ▁Sen, ti, ment, ▁Tree, bank, ▁movi...           54   \n","586                                           [BL, EU]          148   \n","591  [▁$, n, $, -, gram, ▁based, ▁similarity, ▁metric]          501   \n","592                       [n, -, gram, ▁based, ▁score]          127   \n","593                  [▁neural, ▁machine, ▁translation]            8   \n","598                                           [90,000]          206   \n","608                                              [▁17]          341   \n","612    [▁strong, ▁retrieval, ▁and, ▁neural, ▁baseline]          323   \n","617                                           [BL, EU]          155   \n","622  [▁it, ▁should, ▁be, ▁highly, ▁correlate, d, ▁w...          231   \n","625                                           [▁24, 4]          175   \n","631  [▁a, ▁real, -, world, ▁chatting, ▁corpus, ▁fro...          292   \n","632  [▁The, ▁dataset, ▁was, ▁crawled, ▁from, ▁the, ...           14   \n","642                                          [english]          142   \n","646  [▁We, ▁also, ▁present, ▁our, ▁dataset, ▁for, ▁...          165   \n","652  [▁These, ▁results, ,, ▁in, ▁addition, ▁to, ▁th...          386   \n","654                                           [BL, EU]          459   \n","655                                           [BL, EU]           89   \n","666                              [▁Content, ▁Fidelity]          171   \n","672        [▁Stanford, ▁Plan, e, ▁, Crash, ▁Data, set]          171   \n","677                    [▁IN, LINE, FOR, M, 0, ▁scores]          232   \n","682                                         [▁Na, ive]          248   \n","683                                       [▁A, ux, NN]           33   \n","688  [▁an, ▁, ut, d, ▁system, ▁is, ▁applied, ▁to, ▁...          137   \n","693  [▁we, ▁follow, ▁the, ▁Kal, di, ▁recipes, ▁for,...          329   \n","694  [▁we, ▁trained, ▁a, ▁separate, ▁, i, -, ve, ct...           40   \n","699  [▁From, ▁the, ▁results, ▁which, ▁we, ▁get, ,, ...          198   \n","702  [▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...          495   \n","703  [▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...          122   \n","707                                               [58]          452   \n","708  [▁58, ▁typically, ▁developing, ▁children, ,, ▁...           81   \n","713  [▁90, ,, 3, 69, ,, 2, 15, ▁tweet, s, ▁written,...          121   \n","718                                       [▁He, xa, F]          158   \n","732                 [ce, c, car, elli, 2013, learning]          178   \n","736                                         [▁Twitter]          454   \n","737                                         [▁Twitter]           83   \n","742  [▁web, -, based, ▁word, ▁association, ▁experim...          176   \n","746                               [▁R, OU, GE, ▁score]          205   \n","751                                     [▁AS, K, f, m]          162   \n","756                            [▁3, ,, 73, 1, ▁movies]          304   \n","763  [▁9, ▁Amazon, ▁product, ▁review, ▁dataset, s, ...          355   \n","768                                         [▁English]          412   \n","769                                         [▁English]           38   \n","773                            [EM, ▁IN, LINE, FOR, M]          252   \n","\n","     end_label                                     correct_answer  \\\n","549        235  we evaluated its performance on the testing da...   \n","553        255                                bag-of-words (BOW),   \n","556        187                            ) the Meta-LSTM BIBREF0   \n","563        284      Daily Mail news articles released by BIBREF9    \n","569        355  large-scale document classification datasets i...   \n","580        432                       Stanford Sentiment Treebank    \n","581         59                       Stanford Sentiment Treebank    \n","586        149                                              BLEU    \n","591        504                                         Self-BLEU,   \n","592        130                                         Self-BLEU,   \n","593          9                                 probability score:   \n","598        208                             150,000 labeled tweets   \n","608        343                         around 100,000 annotations   \n","612        324                                               GPT2   \n","617        164                         SciBERT model of BIBREF11    \n","622        324  The first one is that it should be highly corr...   \n","625        175                                                244   \n","631        299              real-world chatting corpus from DuMi,   \n","632         23  unlabeled massive dataset of conversation utte...   \n","642        142                                           english    \n","646        189  We also present our dataset for public researc...   \n","652        413  number of epochs is an important parameter and...   \n","654        460                                              BLEU    \n","655         90                                              BLEU    \n","666        176                             Content Fidelity (CF)    \n","672        182             Stanford Plane Crash Dataset BIBREF15    \n","677        237                                INLINEFORM0 scores    \n","682        252                                         (1) Naive:   \n","683         42                                  (4) AuxNN BIBREF4   \n","688        186  Extracting cae features requires three steps, ...   \n","693        343          train a tdnn BIBREF36 with block softmax    \n","694         58  tdnn has six 625-dimensional hidden layers fol...   \n","699        220  transformer model achieves higher BLEU score t...   \n","702        506  1000 conversations composed of 6833 sentences ...   \n","703        133  1000 conversations composed of 6833 sentences ...   \n","707        452                                                58    \n","708         81                                                58    \n","713        141  90,369,215 tweets written in French, posted by...   \n","718        179  we compare the label accuracy of “SUPPORTS” la...   \n","732        196  a benchmark dataset created by ceccarelli2013l...   \n","736        454                                           Twitter.   \n","737         83                                           Twitter.   \n","742        197  words length distribution, the frequency of us...   \n","746        226       F-measures of ROUGE-1, ROUGE-2 and ROUGE-SU4   \n","751        167                       social networking site ASKfm   \n","756        327  3,731 movies; for each movie we are given a la...   \n","763        364  9 Amazon product review datasets for 9 differe...   \n","768        412                                           English    \n","769         38                                           English    \n","773        257                                    EM INLINEFORM0    \n","\n","                                         correct_token  NoAnsw  \n","549  [▁we, ▁evaluated, ▁its, ▁performance, ▁on, ▁th...   False  \n","553          [▁bag, -, of, -, word, s, ▁, (, BO, W, )]   False  \n","556         [), ▁the, ▁Meta, -, LS, TM, ▁, BI, BR, EF]   False  \n","563  [▁Daily, ▁Mail, ▁news, ▁articles, ▁released, ▁...   False  \n","569  [▁large, -, scale, ▁document, ▁classification,...   False  \n","580           [▁Stanford, ▁Sen, ti, ment, ▁Tree, bank]   False  \n","581           [▁Stanford, ▁Sen, ti, ment, ▁Tree, bank]   False  \n","586                                           [BL, EU]   False  \n","591                                 [▁Self, -, BL, EU]   False  \n","592                                 [▁Self, -, BL, EU]   False  \n","593                             [▁probability, ▁score]   False  \n","598                       [▁150,000, ▁labeled, ▁tweet]   False  \n","608                   [▁around, ▁100,000, ▁annotation]   False  \n","612                                           [▁G, PT]   False  \n","617     [▁Sci, BER, T, ▁model, ▁of, ▁, BI, BR, EF, 11]   False  \n","622  [▁The, ▁first, ▁one, ▁is, ▁that, ▁it, ▁should,...   False  \n","625                                              [▁24]   False  \n","631  [▁real, -, world, ▁chatting, ▁corpus, ▁from, ▁...   False  \n","632  [▁un, label, ed, ▁massive, ▁dataset, ▁of, ▁con...   False  \n","642                                          [english]   False  \n","646  [▁We, ▁also, ▁present, ▁our, ▁dataset, ▁for, ▁...   False  \n","652  [▁number, ▁of, ▁epoch, s, ▁is, ▁an, ▁important...   False  \n","654                                           [BL, EU]   False  \n","655                                           [BL, EU]   False  \n","666                 [▁Content, ▁Fidelity, ▁, (, CF, )]   False  \n","672  [▁Stanford, ▁Plan, e, ▁, Crash, ▁Data, set, ▁,...   False  \n","677                    [▁IN, LINE, FOR, M, 0, ▁scores]   False  \n","682                                [(, 1, ), ▁Na, ive]   False  \n","683               [(, 4, ), ▁A, ux, NN, ▁, BI, BR, EF]   False  \n","688  [▁Extract, ing, ▁ca, e, ▁features, ▁requires, ...   False  \n","693  [▁train, ▁a, ▁, t, d, nn, ▁, BI, BR, EF, 36, ▁...   False  \n","694  [t, d, nn, ▁has, ▁six, ▁, 625, -, dimensional,...   False  \n","699  [▁transform, er, ▁model, ▁achieve, s, ▁higher,...   False  \n","702  [▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...   False  \n","703  [▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...   False  \n","707                                               [58]   False  \n","708                                               [58]   False  \n","713  [▁90, ,, 3, 69, ,, 2, 15, ▁tweet, s, ▁written,...   False  \n","718  [▁we, ▁compare, ▁the, ▁label, ▁accuracy, ▁of, ...   False  \n","732  [▁a, ▁benchmark, ▁dataset, ▁created, ▁by, ▁, c...   False  \n","736                                         [▁Twitter]   False  \n","737                                         [▁Twitter]   False  \n","742  [▁words, ▁length, ▁distribution, ,, ▁the, ▁fre...   False  \n","746  [▁F, -, measure, s, ▁of, ▁R, OU, GE, -, 1, ,, ...   False  \n","751           [▁social, ▁networking, ▁site, ▁AS, K, f]   False  \n","756  [▁3, ,, 73, 1, ▁movies, ;, ▁for, ▁each, ▁movie...   False  \n","763  [▁9, ▁Amazon, ▁product, ▁review, ▁dataset, s, ...   False  \n","768                                         [▁English]   False  \n","769                                         [▁English]   False  \n","773                         [EM, ▁IN, LINE, FOR, M, 0]   False  "],"text/html":["\n","  <div id=\"df-652a1d2a-b7b1-4af3-947f-c8a5f8ec5c93\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score_diff</th>\n","      <th>pred_start</th>\n","      <th>pred_end</th>\n","      <th>pred_answer</th>\n","      <th>pred_token</th>\n","      <th>start_label</th>\n","      <th>end_label</th>\n","      <th>correct_answer</th>\n","      <th>correct_token</th>\n","      <th>NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>549</th>\n","      <td>-1.885360</td>\n","      <td>218</td>\n","      <td>232</td>\n","      <td>R, RMSE, MSE, bias, and computational time com...</td>\n","      <td>[▁R, ,, ▁, RM, SE, ,, ▁M, SE, ,, ▁bias, ,, ▁an...</td>\n","      <td>208</td>\n","      <td>235</td>\n","      <td>we evaluated its performance on the testing da...</td>\n","      <td>[▁we, ▁evaluated, ▁its, ▁performance, ▁on, ▁th...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>553</th>\n","      <td>-3.145474</td>\n","      <td>245</td>\n","      <td>277</td>\n","      <td>bag-of-words (BOW), term frequency–inverse doc...</td>\n","      <td>[▁bag, -, of, -, word, s, ▁, (, BO, W, ), ,, ▁...</td>\n","      <td>245</td>\n","      <td>255</td>\n","      <td>bag-of-words (BOW),</td>\n","      <td>[▁bag, -, of, -, word, s, ▁, (, BO, W, )]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>556</th>\n","      <td>-2.815018</td>\n","      <td>180</td>\n","      <td>183</td>\n","      <td>Meta-LSTM</td>\n","      <td>[▁Meta, -, LS, TM]</td>\n","      <td>178</td>\n","      <td>187</td>\n","      <td>) the Meta-LSTM BIBREF0</td>\n","      <td>[), ▁the, ▁Meta, -, LS, TM, ▁, BI, BR, EF]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>563</th>\n","      <td>-6.857100</td>\n","      <td>274</td>\n","      <td>283</td>\n","      <td>Daily Mail news articles released by BIBREF</td>\n","      <td>[▁Daily, ▁Mail, ▁news, ▁articles, ▁released, ▁...</td>\n","      <td>274</td>\n","      <td>284</td>\n","      <td>Daily Mail news articles released by BIBREF9</td>\n","      <td>[▁Daily, ▁Mail, ▁news, ▁articles, ▁released, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>569</th>\n","      <td>2.232587</td>\n","      <td>339</td>\n","      <td>367</td>\n","      <td>three of the large-scale document classificati...</td>\n","      <td>[▁three, ▁of, ▁the, ▁large, -, scale, ▁documen...</td>\n","      <td>342</td>\n","      <td>355</td>\n","      <td>large-scale document classification datasets i...</td>\n","      <td>[▁large, -, scale, ▁document, ▁classification,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>580</th>\n","      <td>-2.373489</td>\n","      <td>427</td>\n","      <td>435</td>\n","      <td>Stanford Sentiment Treebank movie reviews dataset</td>\n","      <td>[▁Stanford, ▁Sen, ti, ment, ▁Tree, bank, ▁movi...</td>\n","      <td>427</td>\n","      <td>432</td>\n","      <td>Stanford Sentiment Treebank</td>\n","      <td>[▁Stanford, ▁Sen, ti, ment, ▁Tree, bank]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>581</th>\n","      <td>-2.002007</td>\n","      <td>54</td>\n","      <td>62</td>\n","      <td>Stanford Sentiment Treebank movie reviews dataset</td>\n","      <td>[▁Stanford, ▁Sen, ti, ment, ▁Tree, bank, ▁movi...</td>\n","      <td>54</td>\n","      <td>59</td>\n","      <td>Stanford Sentiment Treebank</td>\n","      <td>[▁Stanford, ▁Sen, ti, ment, ▁Tree, bank]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>586</th>\n","      <td>-1.429255</td>\n","      <td>148</td>\n","      <td>149</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>148</td>\n","      <td>149</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>591</th>\n","      <td>0.754134</td>\n","      <td>266</td>\n","      <td>273</td>\n","      <td>$n$-gram based similarity metric</td>\n","      <td>[▁$, n, $, -, gram, ▁based, ▁similarity, ▁metric]</td>\n","      <td>501</td>\n","      <td>504</td>\n","      <td>Self-BLEU,</td>\n","      <td>[▁Self, -, BL, EU]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>592</th>\n","      <td>0.171875</td>\n","      <td>363</td>\n","      <td>367</td>\n","      <td>n-gram based score</td>\n","      <td>[n, -, gram, ▁based, ▁score]</td>\n","      <td>127</td>\n","      <td>130</td>\n","      <td>Self-BLEU,</td>\n","      <td>[▁Self, -, BL, EU]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>593</th>\n","      <td>2.322204</td>\n","      <td>392</td>\n","      <td>394</td>\n","      <td>neural machine translation</td>\n","      <td>[▁neural, ▁machine, ▁translation]</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>probability score:</td>\n","      <td>[▁probability, ▁score]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>598</th>\n","      <td>8.065354</td>\n","      <td>144</td>\n","      <td>144</td>\n","      <td>90,000</td>\n","      <td>[90,000]</td>\n","      <td>206</td>\n","      <td>208</td>\n","      <td>150,000 labeled tweets</td>\n","      <td>[▁150,000, ▁labeled, ▁tweet]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>0.327970</td>\n","      <td>231</td>\n","      <td>231</td>\n","      <td>17</td>\n","      <td>[▁17]</td>\n","      <td>341</td>\n","      <td>343</td>\n","      <td>around 100,000 annotations</td>\n","      <td>[▁around, ▁100,000, ▁annotation]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>612</th>\n","      <td>1.062492</td>\n","      <td>296</td>\n","      <td>300</td>\n","      <td>strong retrieval and neural baseline</td>\n","      <td>[▁strong, ▁retrieval, ▁and, ▁neural, ▁baseline]</td>\n","      <td>323</td>\n","      <td>324</td>\n","      <td>GPT2</td>\n","      <td>[▁G, PT]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>617</th>\n","      <td>-0.651468</td>\n","      <td>499</td>\n","      <td>500</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>155</td>\n","      <td>164</td>\n","      <td>SciBERT model of BIBREF11</td>\n","      <td>[▁Sci, BER, T, ▁model, ▁of, ▁, BI, BR, EF, 11]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>622</th>\n","      <td>-3.998379</td>\n","      <td>236</td>\n","      <td>246</td>\n","      <td>it should be highly correlated with human judg...</td>\n","      <td>[▁it, ▁should, ▁be, ▁highly, ▁correlate, d, ▁w...</td>\n","      <td>231</td>\n","      <td>324</td>\n","      <td>The first one is that it should be highly corr...</td>\n","      <td>[▁The, ▁first, ▁one, ▁is, ▁that, ▁it, ▁should,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>625</th>\n","      <td>-4.603097</td>\n","      <td>175</td>\n","      <td>176</td>\n","      <td>244</td>\n","      <td>[▁24, 4]</td>\n","      <td>175</td>\n","      <td>175</td>\n","      <td>244</td>\n","      <td>[▁24]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>631</th>\n","      <td>-5.748355</td>\n","      <td>291</td>\n","      <td>299</td>\n","      <td>a real-world chatting corpus from DuMi</td>\n","      <td>[▁a, ▁real, -, world, ▁chatting, ▁corpus, ▁fro...</td>\n","      <td>292</td>\n","      <td>299</td>\n","      <td>real-world chatting corpus from DuMi,</td>\n","      <td>[▁real, -, world, ▁chatting, ▁corpus, ▁from, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>632</th>\n","      <td>0.049258</td>\n","      <td>38</td>\n","      <td>46</td>\n","      <td>The dataset was crawled from the Douban forum</td>\n","      <td>[▁The, ▁dataset, ▁was, ▁crawled, ▁from, ▁the, ...</td>\n","      <td>14</td>\n","      <td>23</td>\n","      <td>unlabeled massive dataset of conversation utte...</td>\n","      <td>[▁un, label, ed, ▁massive, ▁dataset, ▁of, ▁con...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>642</th>\n","      <td>-0.137658</td>\n","      <td>142</td>\n","      <td>142</td>\n","      <td>english</td>\n","      <td>[english]</td>\n","      <td>142</td>\n","      <td>142</td>\n","      <td>english</td>\n","      <td>[english]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>646</th>\n","      <td>5.025795</td>\n","      <td>165</td>\n","      <td>172</td>\n","      <td>We also present our dataset for public research</td>\n","      <td>[▁We, ▁also, ▁present, ▁our, ▁dataset, ▁for, ▁...</td>\n","      <td>165</td>\n","      <td>189</td>\n","      <td>We also present our dataset for public researc...</td>\n","      <td>[▁We, ▁also, ▁present, ▁our, ▁dataset, ▁for, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>652</th>\n","      <td>14.055028</td>\n","      <td>324</td>\n","      <td>379</td>\n","      <td>These results, in addition to the number of le...</td>\n","      <td>[▁These, ▁results, ,, ▁in, ▁addition, ▁to, ▁th...</td>\n","      <td>386</td>\n","      <td>413</td>\n","      <td>number of epochs is an important parameter and...</td>\n","      <td>[▁number, ▁of, ▁epoch, s, ▁is, ▁an, ▁important...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>654</th>\n","      <td>0.555589</td>\n","      <td>459</td>\n","      <td>460</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>459</td>\n","      <td>460</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>655</th>\n","      <td>1.031443</td>\n","      <td>89</td>\n","      <td>90</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>89</td>\n","      <td>90</td>\n","      <td>BLEU</td>\n","      <td>[BL, EU]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>666</th>\n","      <td>-2.958414</td>\n","      <td>171</td>\n","      <td>172</td>\n","      <td>Content Fidelity</td>\n","      <td>[▁Content, ▁Fidelity]</td>\n","      <td>171</td>\n","      <td>176</td>\n","      <td>Content Fidelity (CF)</td>\n","      <td>[▁Content, ▁Fidelity, ▁, (, CF, )]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>672</th>\n","      <td>-7.635859</td>\n","      <td>171</td>\n","      <td>177</td>\n","      <td>Stanford Plane Crash Dataset</td>\n","      <td>[▁Stanford, ▁Plan, e, ▁, Crash, ▁Data, set]</td>\n","      <td>171</td>\n","      <td>182</td>\n","      <td>Stanford Plane Crash Dataset BIBREF15</td>\n","      <td>[▁Stanford, ▁Plan, e, ▁, Crash, ▁Data, set, ▁,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>677</th>\n","      <td>6.474312</td>\n","      <td>232</td>\n","      <td>237</td>\n","      <td>INLINEFORM0 scores</td>\n","      <td>[▁IN, LINE, FOR, M, 0, ▁scores]</td>\n","      <td>232</td>\n","      <td>237</td>\n","      <td>INLINEFORM0 scores</td>\n","      <td>[▁IN, LINE, FOR, M, 0, ▁scores]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>682</th>\n","      <td>-5.391022</td>\n","      <td>251</td>\n","      <td>252</td>\n","      <td>Naive</td>\n","      <td>[▁Na, ive]</td>\n","      <td>248</td>\n","      <td>252</td>\n","      <td>(1) Naive:</td>\n","      <td>[(, 1, ), ▁Na, ive]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>683</th>\n","      <td>-2.247106</td>\n","      <td>36</td>\n","      <td>38</td>\n","      <td>AuxNN</td>\n","      <td>[▁A, ux, NN]</td>\n","      <td>33</td>\n","      <td>42</td>\n","      <td>(4) AuxNN BIBREF4</td>\n","      <td>[(, 4, ), ▁A, ux, NN, ▁, BI, BR, EF]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>688</th>\n","      <td>-1.751326</td>\n","      <td>158</td>\n","      <td>186</td>\n","      <td>an utd system is applied to the target languag...</td>\n","      <td>[▁an, ▁, ut, d, ▁system, ▁is, ▁applied, ▁to, ▁...</td>\n","      <td>137</td>\n","      <td>186</td>\n","      <td>Extracting cae features requires three steps, ...</td>\n","      <td>[▁Extract, ing, ▁ca, e, ▁features, ▁requires, ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>693</th>\n","      <td>5.133382</td>\n","      <td>259</td>\n","      <td>296</td>\n","      <td>we follow the Kaldi recipes for the GlobalPhon...</td>\n","      <td>[▁we, ▁follow, ▁the, ▁Kal, di, ▁recipes, ▁for,...</td>\n","      <td>329</td>\n","      <td>343</td>\n","      <td>train a tdnn BIBREF36 with block softmax</td>\n","      <td>[▁train, ▁a, ▁, t, d, nn, ▁, BI, BR, EF, 36, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>694</th>\n","      <td>2.680057</td>\n","      <td>167</td>\n","      <td>186</td>\n","      <td>we trained a separate i-vector extractor for e...</td>\n","      <td>[▁we, ▁trained, ▁a, ▁separate, ▁, i, -, ve, ct...</td>\n","      <td>40</td>\n","      <td>58</td>\n","      <td>tdnn has six 625-dimensional hidden layers fol...</td>\n","      <td>[t, d, nn, ▁has, ▁six, ▁, 625, -, dimensional,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>3.410821</td>\n","      <td>186</td>\n","      <td>220</td>\n","      <td>From the results which we get, it is evident t...</td>\n","      <td>[▁From, ▁the, ▁results, ▁which, ▁we, ▁get, ,, ...</td>\n","      <td>198</td>\n","      <td>220</td>\n","      <td>transformer model achieves higher BLEU score t...</td>\n","      <td>[▁transform, er, ▁model, ▁achieve, s, ▁higher,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>702</th>\n","      <td>-3.777361</td>\n","      <td>495</td>\n","      <td>507</td>\n","      <td>1000 conversations composed of 6833 sentences ...</td>\n","      <td>[▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...</td>\n","      <td>495</td>\n","      <td>506</td>\n","      <td>1000 conversations composed of 6833 sentences ...</td>\n","      <td>[▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>703</th>\n","      <td>-4.740989</td>\n","      <td>122</td>\n","      <td>134</td>\n","      <td>1000 conversations composed of 6833 sentences ...</td>\n","      <td>[▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...</td>\n","      <td>122</td>\n","      <td>133</td>\n","      <td>1000 conversations composed of 6833 sentences ...</td>\n","      <td>[▁1000, ▁conversations, ▁composed, ▁of, ▁68, 3...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>707</th>\n","      <td>3.400307</td>\n","      <td>452</td>\n","      <td>452</td>\n","      <td>58</td>\n","      <td>[58]</td>\n","      <td>452</td>\n","      <td>452</td>\n","      <td>58</td>\n","      <td>[58]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>708</th>\n","      <td>1.543939</td>\n","      <td>153</td>\n","      <td>170</td>\n","      <td>58 typically developing children, aged 5-12 ye...</td>\n","      <td>[▁58, ▁typically, ▁developing, ▁children, ,, ▁...</td>\n","      <td>81</td>\n","      <td>81</td>\n","      <td>58</td>\n","      <td>[58]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>713</th>\n","      <td>-4.137244</td>\n","      <td>121</td>\n","      <td>132</td>\n","      <td>90,369,215 tweets written in French</td>\n","      <td>[▁90, ,, 3, 69, ,, 2, 15, ▁tweet, s, ▁written,...</td>\n","      <td>121</td>\n","      <td>141</td>\n","      <td>90,369,215 tweets written in French, posted by...</td>\n","      <td>[▁90, ,, 3, 69, ,, 2, 15, ▁tweet, s, ▁written,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>718</th>\n","      <td>1.946070</td>\n","      <td>178</td>\n","      <td>180</td>\n","      <td>HexaF</td>\n","      <td>[▁He, xa, F]</td>\n","      <td>158</td>\n","      <td>179</td>\n","      <td>we compare the label accuracy of “SUPPORTS” la...</td>\n","      <td>[▁we, ▁compare, ▁the, ▁label, ▁accuracy, ▁of, ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>732</th>\n","      <td>-3.921979</td>\n","      <td>184</td>\n","      <td>189</td>\n","      <td>ceccarelli2013learning</td>\n","      <td>[ce, c, car, elli, 2013, learning]</td>\n","      <td>178</td>\n","      <td>196</td>\n","      <td>a benchmark dataset created by ceccarelli2013l...</td>\n","      <td>[▁a, ▁benchmark, ▁dataset, ▁created, ▁by, ▁, c...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>736</th>\n","      <td>0.881764</td>\n","      <td>454</td>\n","      <td>454</td>\n","      <td>Twitter</td>\n","      <td>[▁Twitter]</td>\n","      <td>454</td>\n","      <td>454</td>\n","      <td>Twitter.</td>\n","      <td>[▁Twitter]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>737</th>\n","      <td>0.903186</td>\n","      <td>83</td>\n","      <td>83</td>\n","      <td>Twitter</td>\n","      <td>[▁Twitter]</td>\n","      <td>83</td>\n","      <td>83</td>\n","      <td>Twitter.</td>\n","      <td>[▁Twitter]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>4.200628</td>\n","      <td>53</td>\n","      <td>62</td>\n","      <td>web-based word association experiment BIBREF</td>\n","      <td>[▁web, -, based, ▁word, ▁association, ▁experim...</td>\n","      <td>176</td>\n","      <td>197</td>\n","      <td>words length distribution, the frequency of us...</td>\n","      <td>[▁words, ▁length, ▁distribution, ,, ▁the, ▁fre...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>746</th>\n","      <td>-5.080938</td>\n","      <td>188</td>\n","      <td>191</td>\n","      <td>ROUGE score</td>\n","      <td>[▁R, OU, GE, ▁score]</td>\n","      <td>205</td>\n","      <td>226</td>\n","      <td>F-measures of ROUGE-1, ROUGE-2 and ROUGE-SU4</td>\n","      <td>[▁F, -, measure, s, ▁of, ▁R, OU, GE, -, 1, ,, ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>751</th>\n","      <td>-4.051925</td>\n","      <td>165</td>\n","      <td>168</td>\n","      <td>ASKfm</td>\n","      <td>[▁AS, K, f, m]</td>\n","      <td>162</td>\n","      <td>167</td>\n","      <td>social networking site ASKfm</td>\n","      <td>[▁social, ▁networking, ▁site, ▁AS, K, f]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>756</th>\n","      <td>-7.127333</td>\n","      <td>304</td>\n","      <td>308</td>\n","      <td>3,731 movies</td>\n","      <td>[▁3, ,, 73, 1, ▁movies]</td>\n","      <td>304</td>\n","      <td>327</td>\n","      <td>3,731 movies; for each movie we are given a la...</td>\n","      <td>[▁3, ,, 73, 1, ▁movies, ;, ▁for, ▁each, ▁movie...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>-1.722377</td>\n","      <td>355</td>\n","      <td>378</td>\n","      <td>9 Amazon product review datasets for 9 differe...</td>\n","      <td>[▁9, ▁Amazon, ▁product, ▁review, ▁dataset, s, ...</td>\n","      <td>355</td>\n","      <td>364</td>\n","      <td>9 Amazon product review datasets for 9 differe...</td>\n","      <td>[▁9, ▁Amazon, ▁product, ▁review, ▁dataset, s, ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>768</th>\n","      <td>0.550560</td>\n","      <td>412</td>\n","      <td>412</td>\n","      <td>English</td>\n","      <td>[▁English]</td>\n","      <td>412</td>\n","      <td>412</td>\n","      <td>English</td>\n","      <td>[▁English]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>769</th>\n","      <td>2.847054</td>\n","      <td>241</td>\n","      <td>241</td>\n","      <td>English</td>\n","      <td>[▁English]</td>\n","      <td>38</td>\n","      <td>38</td>\n","      <td>English</td>\n","      <td>[▁English]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>773</th>\n","      <td>-3.151261</td>\n","      <td>252</td>\n","      <td>256</td>\n","      <td>EM INLINEFORM</td>\n","      <td>[EM, ▁IN, LINE, FOR, M]</td>\n","      <td>252</td>\n","      <td>257</td>\n","      <td>EM INLINEFORM0</td>\n","      <td>[EM, ▁IN, LINE, FOR, M, 0]</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-652a1d2a-b7b1-4af3-947f-c8a5f8ec5c93')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-652a1d2a-b7b1-4af3-947f-c8a5f8ec5c93 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-652a1d2a-b7b1-4af3-947f-c8a5f8ec5c93');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":106}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6a8IdclX0NCc"},"outputs":[],"source":["import collections\n","\n","def compute_f1(gold_toks, pred_toks):\n","    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","    num_same = sum(common.values())\n","    if len(gold_toks) == 0 or len(pred_toks) == 0:\n","        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","        return int(gold_toks == pred_toks)\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(pred_toks)\n","    recall = 1.0 * num_same / len(gold_toks)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGUyIeK60f1U"},"outputs":[],"source":["def get_f1_df(preds_df):\n","    f1_data = {\"threshold\": [], \"f1\":[], \"f1_Answ\":[], \"f1_NoAnsw\":[]}\n","\n","    for threshold in np.arange(-3, 10, 1):\n","        temp = preds_df.copy()\n","        temp[\"pred_token\"] = temp.apply(lambda row: row[\"pred_token\"] if row[\"score_diff\"] < threshold else [\"<cls>\"], axis=1)\n","        temp[\"f1\"] = temp.apply(lambda r: compute_f1(r[\"correct_token\"], r[\"pred_token\"]), axis=1)\n","\n","        f1_total = 100 * np.mean(temp[\"f1\"])\n","        f1_scores = list(100 * temp.groupby(\"NoAnsw\").agg([\"mean\"])[\"f1\"][\"mean\"])\n","        \n","        f1_data[\"threshold\"].append(threshold)\n","        f1_data[\"f1\"].append(f1_total)\n","        f1_data[\"f1_Answ\"].append(f1_scores[0])\n","        f1_data[\"f1_NoAnsw\"].append(f1_scores[1])\n","\n","    df_scores = pd.DataFrame(f1_data)\n","\n","    return df_scores\n","val_scores = get_f1_df(val_preds_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1653859425847,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"UQ9-n1VocNsT","outputId":"46f9d509-b3e2-49b3-cf0a-9e5d063c5026"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["    threshold         f1    f1_Answ  f1_NoAnsw\n","0          -3  79.146385  18.403899  98.807496\n","1          -2  79.966091  24.387647  97.955707\n","2          -1  79.942347  27.448440  96.933560\n","3           0  78.859817  30.389885  94.548552\n","4           1  78.526388  35.868437  92.333901\n","5           2  76.585969  38.459463  88.926746\n","6           3  73.493647  40.550337  84.156729\n","7           4  70.926550  42.683839  80.068143\n","8           5  66.940962  43.753301  74.446337\n","9           6  63.291302  44.617586  69.335605\n","10          7  58.164972  45.758860  62.180579\n","11          8  53.421453  46.360364  55.706985\n","12          9  49.560449  46.360364  50.596252"],"text/html":["\n","  <div id=\"df-f4de3cc8-fdba-4baf-abfe-99af2ed00f29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>f1</th>\n","      <th>f1_Answ</th>\n","      <th>f1_NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-3</td>\n","      <td>79.146385</td>\n","      <td>18.403899</td>\n","      <td>98.807496</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-2</td>\n","      <td>79.966091</td>\n","      <td>24.387647</td>\n","      <td>97.955707</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1</td>\n","      <td>79.942347</td>\n","      <td>27.448440</td>\n","      <td>96.933560</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>78.859817</td>\n","      <td>30.389885</td>\n","      <td>94.548552</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>78.526388</td>\n","      <td>35.868437</td>\n","      <td>92.333901</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>76.585969</td>\n","      <td>38.459463</td>\n","      <td>88.926746</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>73.493647</td>\n","      <td>40.550337</td>\n","      <td>84.156729</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4</td>\n","      <td>70.926550</td>\n","      <td>42.683839</td>\n","      <td>80.068143</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>66.940962</td>\n","      <td>43.753301</td>\n","      <td>74.446337</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>6</td>\n","      <td>63.291302</td>\n","      <td>44.617586</td>\n","      <td>69.335605</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>7</td>\n","      <td>58.164972</td>\n","      <td>45.758860</td>\n","      <td>62.180579</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>8</td>\n","      <td>53.421453</td>\n","      <td>46.360364</td>\n","      <td>55.706985</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>9</td>\n","      <td>49.560449</td>\n","      <td>46.360364</td>\n","      <td>50.596252</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4de3cc8-fdba-4baf-abfe-99af2ed00f29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f4de3cc8-fdba-4baf-abfe-99af2ed00f29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f4de3cc8-fdba-4baf-abfe-99af2ed00f29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":69}],"source":["val_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBpEVe3GnpP7"},"outputs":[],"source":["val_scores.to_csv(\"/content/drive/MyDrive/SEW.NLP/Edoardo B 48 LR 5e-5_val_scores_xlnet_.csv\")"]},{"cell_type":"code","source":["val_scores = pd.read_csv(\"/content/drive/MyDrive/SEW.NLP/Edoardo B 48 LR 5e-5_val_scores_xlnet_.csv\", index_col=0)"],"metadata":{"id":"gdZG-tTmNzuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"mpWQcgZjN4mm","executionInfo":{"status":"ok","timestamp":1653868058069,"user_tz":420,"elapsed":292,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"df436b9c-1bd1-494a-8793-f1a082f3c907"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    threshold         f1    f1_Answ  f1_NoAnsw\n","0          -3  79.146385  18.403899  98.807496\n","1          -2  79.966091  24.387647  97.955707\n","2          -1  79.942347  27.448440  96.933560\n","3           0  78.859817  30.389885  94.548552\n","4           1  78.526388  35.868437  92.333901\n","5           2  76.585969  38.459463  88.926746\n","6           3  73.493647  40.550337  84.156729\n","7           4  70.926550  42.683839  80.068143\n","8           5  66.940962  43.753301  74.446337\n","9           6  63.291302  44.617586  69.335605\n","10          7  58.164972  45.758860  62.180579\n","11          8  53.421453  46.360364  55.706985\n","12          9  49.560449  46.360364  50.596252"],"text/html":["\n","  <div id=\"df-d70947d8-17aa-426e-80ce-1ca00e15492a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>f1</th>\n","      <th>f1_Answ</th>\n","      <th>f1_NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-3</td>\n","      <td>79.146385</td>\n","      <td>18.403899</td>\n","      <td>98.807496</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-2</td>\n","      <td>79.966091</td>\n","      <td>24.387647</td>\n","      <td>97.955707</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1</td>\n","      <td>79.942347</td>\n","      <td>27.448440</td>\n","      <td>96.933560</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>78.859817</td>\n","      <td>30.389885</td>\n","      <td>94.548552</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>78.526388</td>\n","      <td>35.868437</td>\n","      <td>92.333901</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>76.585969</td>\n","      <td>38.459463</td>\n","      <td>88.926746</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>73.493647</td>\n","      <td>40.550337</td>\n","      <td>84.156729</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4</td>\n","      <td>70.926550</td>\n","      <td>42.683839</td>\n","      <td>80.068143</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>66.940962</td>\n","      <td>43.753301</td>\n","      <td>74.446337</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>6</td>\n","      <td>63.291302</td>\n","      <td>44.617586</td>\n","      <td>69.335605</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>7</td>\n","      <td>58.164972</td>\n","      <td>45.758860</td>\n","      <td>62.180579</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>8</td>\n","      <td>53.421453</td>\n","      <td>46.360364</td>\n","      <td>55.706985</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>9</td>\n","      <td>49.560449</td>\n","      <td>46.360364</td>\n","      <td>50.596252</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d70947d8-17aa-426e-80ce-1ca00e15492a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d70947d8-17aa-426e-80ce-1ca00e15492a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d70947d8-17aa-426e-80ce-1ca00e15492a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["val_scores"],"metadata":{"id":"GoAhwfH1OtfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","figure, ax = plt.subplots(nrows=1, ncols=1, figsize=(11,5))\n","ax.title.set_text(\"Validation Results XLNet\")\n","\n","ax.set_facecolor('#EBEBEB')\n","# Remove border around plot.\n","[ax.spines[side].set_visible(False) for side in ax.spines]\n","# Style the grid.\n","ax.grid(which='major', color='white', linewidth=1.2)\n","ax.grid(which='minor', color='white', linewidth=0.6)\n","# Show the minor ticks and grid.\n","ax.minorticks_on()\n","# Now hide the minor ticks (but leave the gridlines).\n","ax.tick_params(which='minor', bottom=False, left=False)\n","\n","\n","ax.plot(val_scores[\"threshold\"], val_scores[\"f1\"], \"-o\", label=\"Total\")\n","ax.plot(val_scores[\"threshold\"], val_scores[\"f1_Answ\"], \"-o\", label=\"Answerable\")\n","ax.plot(val_scores[\"threshold\"], val_scores[\"f1_NoAnsw\"], \"-o\", label=\"NonAnswerable\")\n","ax.set_xlabel(\"Threshold\")\n","ax.set_ylabel(\"F1-Score\")\n","ax.set_xticks(np.array(val_scores[\"threshold\"])[::2])\n","ax.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"uBr5QoYiN-Nn","executionInfo":{"status":"ok","timestamp":1653872426858,"user_tz":420,"elapsed":859,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"ebd52ea5-da85-49e1-fc06-07909f3ba4be"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 792x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"7k_vTyuqNzeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rHlLsT7tDMQE"},"outputs":[],"source":["## Pick a threshold with decent f1 and good f1_Answ, like 3 or 4\n","threshold = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"elapsed":32941,"status":"ok","timestamp":1653873215581,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"oH6Ll42RDi-V","outputId":"d1f28d08-90fb-4e4f-92a4-355291027791"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 823\n","  Batch size = 8\n","The following columns in the test set don't have a corresponding argument in `XLNetForQuestionAnsweringSimple.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `XLNetForQuestionAnsweringSimple.forward`,  you can safely ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [103/103 00:32]\n","    </div>\n","    "]},"metadata":{}}],"source":["best_trainer = Trainer(\n","    best_model,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= test_dataset,\n","    data_collator=data_collator\n",")\n","\n","test_predictions = best_trainer.predict(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcFIoknpEd0u"},"outputs":[],"source":["test_preds_df = get_preds_df(test_predictions, df_test, df_test_tokenized, test_dataset)"]},{"cell_type":"code","source":["test_preds_df[test_preds_df[\"correct_answer\"] != \"\"].head(50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9W4ikFRchqQA","executionInfo":{"status":"ok","timestamp":1653873292901,"user_tz":420,"elapsed":317,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"dfae52a1-45cc-41ca-8f3e-da60c0f0e1aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     score_diff  pred_start  pred_end  \\\n","2      3.288438         100       111   \n","5      2.774209         178       186   \n","11     0.690770         177       192   \n","12     5.162405          26        36   \n","16     1.455661         239       252   \n","20     1.479667         260       262   \n","21     6.297492          38        38   \n","22     6.848415         313       316   \n","23     1.881864         150       151   \n","26     6.533589         426       431   \n","27     3.488737          18        58   \n","35    -2.671763         211       211   \n","40     1.519102         496       498   \n","41     8.049353         121       123   \n","45    -0.500149         461       464   \n","46    -4.715342          88        91   \n","51     2.212003         168       173   \n","60    -5.827104         349       360   \n","61    -2.593458          24        26   \n","65    10.192525         225       306   \n","66     4.036395         301       308   \n","71     3.068229         282       308   \n","76    -2.845131         260       283   \n","82    -1.042876         407       414   \n","83    -0.495009          28        53   \n","86    -1.110858         480       500   \n","87    -2.618403         109       129   \n","91     1.635480         156       174   \n","98     2.167394         491       494   \n","102   -3.222356         184       187   \n","103   -2.512972         284       286   \n","104    8.621204          14        40   \n","107    3.157374         423       435   \n","108    0.657291          61        62   \n","109    0.856071         154       164   \n","113    1.430742         469       483   \n","114    2.467003          97       111   \n","119    3.897552          39       248   \n","122    3.779297          69        80   \n","129    0.375621         357       370   \n","133   -0.204527         334       339   \n","135    1.956522         205       205   \n","140   -1.954571         204       207   \n","143   10.917922         107       256   \n","150   -4.409177         393       401   \n","151   -2.879325          18        26   \n","154   -1.216578         323       326   \n","158    6.575477         225       239   \n","169    7.952720         403       447   \n","170   12.889774         182       214   \n","\n","                                           pred_answer  \\\n","2    ATIS (Airline Travel Information Systems) dataset   \n","5                               #LokSabhaElections2019   \n","11                   Active Users of set $\\mathbf {S}$   \n","12   username, display name, profile image, locatio...   \n","16   To address the need for a large and high-quali...   \n","20                                               SQuAD   \n","21                                                  MT   \n","22                                          multi-BERT   \n","23                                                BERT   \n","26                                         Cora, arXiv   \n","27   user profiles or their online posts on social ...   \n","35                                                Cora   \n","40                                              BIBREF   \n","41                                              BIBREF   \n","45                                   20K news articles   \n","46                                   20K news articles   \n","51                                         WW BIBREF19   \n","60                                 CoNLL-YAGO BIBREF22   \n","61                                             TAC2010   \n","65   rhetorical annotation scheme which takes into ...   \n","66     position of sentence, sentence length and tense   \n","71   a dataset of 20194 cleaned, unique tweets iden...   \n","76   Books (B), DVDs (D), Electronics (E) and Kitch...   \n","82                        Car, Phone, Notebook, Camera   \n","83   BIBREF35, BIBREF36, BIBREF29 (Car, Phone, Note...   \n","86   raw text, text cleaning through document logic...   \n","87   raw text, text cleaning through document logic...   \n","91   12 subtrees with 5247 synsets and 3. 2 million...   \n","98                                        SemEval 2019   \n","102                                           F1-score   \n","103                              Task completion ratio   \n","104  Guidance ability for out of scope input: There...   \n","107  rodent uterotrophic bioassay data extracted fr...   \n","108                              research publications   \n","109  PDFs were provided to us by the database creators   \n","113  no impact, low impact, medium impact, high imp...   \n","114  no impact, low impact, medium impact, high imp...   \n","119  MLQA is a multi-way parallel extractive QA eva...   \n","122  we proposed a dataset for emotion classificati...   \n","129  randomly assigning any of the sentiment values...   \n","133                       English, Arabic, and Spanish   \n","135                                            Spanish   \n","140                    ancient Chinese history records   \n","143  manually labeled data. It also improves superv...   \n","150        6,138 pieces of logical reasoning questions   \n","151        6,138 pieces of logical reasoning questions   \n","154                                              6,138   \n","158  It learns the sample weights from the auxiliar...   \n","169  $(Q^{k},P^{k},A^{k})$ to represent a data poin...   \n","170  Section \" Experiment Details\" ) using question...   \n","\n","                                            pred_token  start_label  \\\n","2    [▁AT, I, S, ▁, (, Air, line, ▁Travel, ▁Informa...          248   \n","5             [#, Lo, k, Sa, bha, Elect, ions, 20, 19]           25   \n","11   [Activ, e, ▁Users, ▁of, ▁set, ▁$, \\, ma, th, b...          398   \n","12   [▁username, ,, ▁display, ▁name, ,, ▁profile, ▁...           26   \n","16   [▁To, ▁address, ▁the, ▁need, ▁for, ▁a, ▁large,...          239   \n","20                                         [S, Qu, AD]          325   \n","21                                                [MT]          367   \n","22                                 [▁multi, -, BER, T]          454   \n","23                                           [▁B, ERT]           81   \n","26                            [▁Cora, ,, ▁, ar, X, iv]          426   \n","27   [▁user, ▁profiles, ▁or, ▁their, ▁online, ▁post...           53   \n","35                                             [▁Cora]          258   \n","40                                        [BI, BR, EF]          490   \n","41                                        [BI, BR, EF]          115   \n","45                          [▁20, K, ▁news, ▁articles]          461   \n","46                          [▁20, K, ▁news, ▁articles]           88   \n","51                             [WW, ▁, BI, BR, EF, 19]          168   \n","60        [▁Co, N, LL, -, Y, A, GO, ▁, BI, BR, EF, 22]          349   \n","61                                      [▁T, AC, 2010]           24   \n","65   [▁rhetorical, ▁annotation, ▁scheme, ▁which, ▁t...          271   \n","66   [▁position, ▁of, ▁sentence, ,, ▁sentence, ▁len...          301   \n","71   [▁a, ▁dataset, ▁of, ▁2019, 4, ▁cleaned, ,, ▁un...          285   \n","76   [▁Books, ▁, (, B, ), ,, ▁DVD, s, ▁, (, D, ), ,...          260   \n","82        [Car, ,, ▁Phone, ,, ▁Note, book, ,, ▁Camera]          407   \n","83   [BI, BR, EF, 35, ,, ▁, BI, BR, EF, 36, ,, ▁, B...           46   \n","86   [▁raw, ▁text, ,, ▁text, ▁cleaning, ▁through, ▁...          480   \n","87   [▁raw, ▁text, ,, ▁text, ▁cleaning, ▁through, ▁...          109   \n","91   [▁12, ▁sub, tree, s, ▁with, ▁52, 47, ▁, syn, s...          125   \n","98                               [▁Sem, E, val, ▁2019]          128   \n","102                                  [▁F, 1, -, score]          178   \n","103                       [▁Task, ▁completion, ▁ratio]          284   \n","104  [▁Gui, d, ance, ▁ability, ▁for, ▁out, ▁of, ▁sc...           14   \n","107  [▁rodent, ▁, uter, o, trophic, ▁bio, assa, y, ...          410   \n","108                         [▁research, ▁publications]           37   \n","109  [▁PDF, s, ▁were, ▁provided, ▁to, ▁us, ▁by, ▁th...           18   \n","113  [▁no, ▁impact, ,, ▁low, ▁impact, ,, ▁medium, ▁...          460   \n","114  [▁no, ▁impact, ,, ▁low, ▁impact, ,, ▁medium, ▁...           88   \n","119  [ML, Q, A, ▁is, ▁a, ▁multi, -, way, ▁parallel,...          188   \n","122  [▁we, ▁proposed, ▁a, ▁dataset, ▁for, ▁emotion,...            9   \n","129  [▁randomly, ▁assign, ing, ▁any, ▁of, ▁the, ▁se...          357   \n","133          [▁English, ,, ▁Arabic, ,, ▁and, ▁Spanish]          334   \n","135                                         [▁Spanish]          259   \n","140           [▁ancient, ▁Chinese, ▁history, ▁records]          204   \n","143  [▁manually, ▁labeled, ▁data, ., ▁It, ▁also, ▁i...           21   \n","150  [▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...          393   \n","151  [▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...           18   \n","154                                     [▁6, ,, 1, 38]          323   \n","158  [▁It, ▁learn, s, ▁the, ▁sample, ▁weight, s, ▁f...          219   \n","169  [▁$, (, Q, ^, {, k, }, ,, P, ^, {, k, }, ,, A,...          388   \n","170  [▁Section, ▁, \", ▁, Experiment, ▁Details, \", ▁...           16   \n","\n","     end_label                                     correct_answer  \\\n","2          251                                   ROMULUS dataset.   \n","5           25                                          username,   \n","11         408  username, display name, profile image, locatio...   \n","12          36  username, display name, profile image, locatio...   \n","16         252  To address the need for a large and high-quali...   \n","20         328                                          BIBREF14    \n","21         372                             pre-trained multi-BERT   \n","22         456                                             QANet    \n","23          83                                             QANet    \n","26         426                                              Cora,   \n","27          53                                              Cora,   \n","35         260                                             Hepth,   \n","40         498                              the ERP data: BIBREF0   \n","41         123                              the ERP data: BIBREF0   \n","45         461                                                20K   \n","46          88                                                20K   \n","51         167                                                 WW   \n","60         355                                        CoNLL-YAGO    \n","61          26                                           TAC2010    \n","65         276       ated sentences with their rhetorical status    \n","66         303                              position of sentence,   \n","71         308  20194 cleaned, unique tweets identified as eit...   \n","76         260                                             Books    \n","82         414                      Car, Phone, Notebook, Camera)   \n","83          53                      Car, Phone, Notebook, Camera)   \n","86         481                                          raw text,   \n","87         110                                          raw text,   \n","91         140  tens of millions of annotated images organized...   \n","98         141  datasets given on the shared task, without usi...   \n","102        187                       For task 1, we use F1-score    \n","103        286                             Task completion ratio:   \n","104         22           Guidance ability for out of scope input:   \n","107        431  a curated database of high-quality in vivo rod...   \n","108         58  a curated database of high-quality in vivo rod...   \n","109         53  GL and non-GL studies consists of 670 publicat...   \n","113        483  5 possible impact labels for a particular clai...   \n","114        111  5 possible impact labels for a particular clai...   \n","119        249  The resulting corpus has between 5,000 and 6,0...   \n","122         63  Sundanese is the second-largest tribe in Indon...   \n","129        370  randomly assigning any of the sentiment values...   \n","133        334                                           English,   \n","135        259                                           English    \n","140        230  ancient Chinese history records in several dyn...   \n","143         21                                          negative    \n","150        401       6,138 pieces of logical reasoning questions,   \n","151         26       6,138 pieces of logical reasoning questions,   \n","154        329                 6,138 logical reasoning questions    \n","158        221                                            BIBREF7   \n","169        391                                          BIBREF26    \n","170         19                                          BIBREF26    \n","\n","                                         correct_token  NoAnsw  \n","2                              [ROM, UL, US, ▁dataset]   False  \n","5                                          [▁username]   False  \n","11   [▁username, ,, ▁display, ▁name, ,, ▁profile, ▁...   False  \n","12   [▁username, ,, ▁display, ▁name, ,, ▁profile, ▁...   False  \n","16   [▁To, ▁address, ▁the, ▁need, ▁for, ▁a, ▁large,...   False  \n","20                                    [BI, BR, EF, 14]   False  \n","21                  [▁pre, -, trained, ▁multi, -, BER]   False  \n","22                                        [▁Q, A, Net]   False  \n","23                                        [▁Q, A, Net]   False  \n","26                                             [▁Cora]   False  \n","27                                             [▁Cora]   False  \n","35                                        [▁He, p, th]   False  \n","40             [▁the, ▁, ERP, ▁data, :, ▁, BI, BR, EF]   False  \n","41             [▁the, ▁, ERP, ▁data, :, ▁, BI, BR, EF]   False  \n","45                                               [▁20]   False  \n","46                                               [▁20]   False  \n","51                                                  []   False  \n","60                           [▁Co, N, LL, -, Y, A, GO]   False  \n","61                                      [▁T, AC, 2010]   False  \n","65   [ated, ▁sentences, ▁with, ▁their, ▁rhetorical,...   False  \n","66                         [▁position, ▁of, ▁sentence]   False  \n","71   [▁2019, 4, ▁cleaned, ,, ▁unique, ▁tweet, s, ▁i...   False  \n","76                                            [▁Books]   False  \n","82        [Car, ,, ▁Phone, ,, ▁Note, book, ,, ▁Camera]   False  \n","83        [Car, ,, ▁Phone, ,, ▁Note, book, ,, ▁Camera]   False  \n","86                                       [▁raw, ▁text]   False  \n","87                                       [▁raw, ▁text]   False  \n","91   [▁tens, ▁of, ▁millions, ▁of, ▁an, not, ated, ▁...   False  \n","98   [▁dataset, s, ▁given, ▁on, ▁the, ▁shared, ▁tas...   False  \n","102   [▁For, ▁task, ▁1, ,, ▁we, ▁use, ▁F, 1, -, score]   False  \n","103                       [▁Task, ▁completion, ▁ratio]   False  \n","104  [▁Gui, d, ance, ▁ability, ▁for, ▁out, ▁of, ▁sc...   False  \n","107  [▁a, ▁, cur, ated, ▁database, ▁of, ▁high, -, q...   False  \n","108  [▁a, ▁, cur, ated, ▁database, ▁of, ▁high, -, q...   False  \n","109  [GL, ▁and, ▁non, -, GL, ▁studies, ▁consists, ▁...   False  \n","113  [▁5, ▁possible, ▁impact, ▁labels, ▁for, ▁a, ▁p...   False  \n","114  [▁5, ▁possible, ▁impact, ▁labels, ▁for, ▁a, ▁p...   False  \n","119  [▁The, ▁resulting, ▁corpus, ▁has, ▁between, ▁5...   False  \n","122  [▁Sun, dan, ese, ▁is, ▁the, ▁second, -, larges...   False  \n","129  [▁randomly, ▁assign, ing, ▁any, ▁of, ▁the, ▁se...   False  \n","133                                         [▁English]   False  \n","135                                         [▁English]   False  \n","140  [▁ancient, ▁Chinese, ▁history, ▁records, ▁in, ...   False  \n","143                                        [▁negative]   False  \n","150  [▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...   False  \n","151  [▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...   False  \n","154   [▁6, ,, 1, 38, ▁logical, ▁reasoning, ▁questions]   False  \n","158                                       [BI, BR, EF]   False  \n","169                                   [BI, BR, EF, 26]   False  \n","170                                   [BI, BR, EF, 26]   False  "],"text/html":["\n","  <div id=\"df-fc042a23-d7ec-4211-91a3-0d3f123d4e72\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score_diff</th>\n","      <th>pred_start</th>\n","      <th>pred_end</th>\n","      <th>pred_answer</th>\n","      <th>pred_token</th>\n","      <th>start_label</th>\n","      <th>end_label</th>\n","      <th>correct_answer</th>\n","      <th>correct_token</th>\n","      <th>NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>3.288438</td>\n","      <td>100</td>\n","      <td>111</td>\n","      <td>ATIS (Airline Travel Information Systems) dataset</td>\n","      <td>[▁AT, I, S, ▁, (, Air, line, ▁Travel, ▁Informa...</td>\n","      <td>248</td>\n","      <td>251</td>\n","      <td>ROMULUS dataset.</td>\n","      <td>[ROM, UL, US, ▁dataset]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.774209</td>\n","      <td>178</td>\n","      <td>186</td>\n","      <td>#LokSabhaElections2019</td>\n","      <td>[#, Lo, k, Sa, bha, Elect, ions, 20, 19]</td>\n","      <td>25</td>\n","      <td>25</td>\n","      <td>username,</td>\n","      <td>[▁username]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.690770</td>\n","      <td>177</td>\n","      <td>192</td>\n","      <td>Active Users of set $\\mathbf {S}$</td>\n","      <td>[Activ, e, ▁Users, ▁of, ▁set, ▁$, \\, ma, th, b...</td>\n","      <td>398</td>\n","      <td>408</td>\n","      <td>username, display name, profile image, locatio...</td>\n","      <td>[▁username, ,, ▁display, ▁name, ,, ▁profile, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5.162405</td>\n","      <td>26</td>\n","      <td>36</td>\n","      <td>username, display name, profile image, locatio...</td>\n","      <td>[▁username, ,, ▁display, ▁name, ,, ▁profile, ▁...</td>\n","      <td>26</td>\n","      <td>36</td>\n","      <td>username, display name, profile image, locatio...</td>\n","      <td>[▁username, ,, ▁display, ▁name, ,, ▁profile, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1.455661</td>\n","      <td>239</td>\n","      <td>252</td>\n","      <td>To address the need for a large and high-quali...</td>\n","      <td>[▁To, ▁address, ▁the, ▁need, ▁for, ▁a, ▁large,...</td>\n","      <td>239</td>\n","      <td>252</td>\n","      <td>To address the need for a large and high-quali...</td>\n","      <td>[▁To, ▁address, ▁the, ▁need, ▁for, ▁a, ▁large,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>1.479667</td>\n","      <td>260</td>\n","      <td>262</td>\n","      <td>SQuAD</td>\n","      <td>[S, Qu, AD]</td>\n","      <td>325</td>\n","      <td>328</td>\n","      <td>BIBREF14</td>\n","      <td>[BI, BR, EF, 14]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>6.297492</td>\n","      <td>38</td>\n","      <td>38</td>\n","      <td>MT</td>\n","      <td>[MT]</td>\n","      <td>367</td>\n","      <td>372</td>\n","      <td>pre-trained multi-BERT</td>\n","      <td>[▁pre, -, trained, ▁multi, -, BER]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>6.848415</td>\n","      <td>313</td>\n","      <td>316</td>\n","      <td>multi-BERT</td>\n","      <td>[▁multi, -, BER, T]</td>\n","      <td>454</td>\n","      <td>456</td>\n","      <td>QANet</td>\n","      <td>[▁Q, A, Net]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>1.881864</td>\n","      <td>150</td>\n","      <td>151</td>\n","      <td>BERT</td>\n","      <td>[▁B, ERT]</td>\n","      <td>81</td>\n","      <td>83</td>\n","      <td>QANet</td>\n","      <td>[▁Q, A, Net]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>6.533589</td>\n","      <td>426</td>\n","      <td>431</td>\n","      <td>Cora, arXiv</td>\n","      <td>[▁Cora, ,, ▁, ar, X, iv]</td>\n","      <td>426</td>\n","      <td>426</td>\n","      <td>Cora,</td>\n","      <td>[▁Cora]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>3.488737</td>\n","      <td>18</td>\n","      <td>58</td>\n","      <td>user profiles or their online posts on social ...</td>\n","      <td>[▁user, ▁profiles, ▁or, ▁their, ▁online, ▁post...</td>\n","      <td>53</td>\n","      <td>53</td>\n","      <td>Cora,</td>\n","      <td>[▁Cora]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>-2.671763</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>Cora</td>\n","      <td>[▁Cora]</td>\n","      <td>258</td>\n","      <td>260</td>\n","      <td>Hepth,</td>\n","      <td>[▁He, p, th]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>1.519102</td>\n","      <td>496</td>\n","      <td>498</td>\n","      <td>BIBREF</td>\n","      <td>[BI, BR, EF]</td>\n","      <td>490</td>\n","      <td>498</td>\n","      <td>the ERP data: BIBREF0</td>\n","      <td>[▁the, ▁, ERP, ▁data, :, ▁, BI, BR, EF]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>8.049353</td>\n","      <td>121</td>\n","      <td>123</td>\n","      <td>BIBREF</td>\n","      <td>[BI, BR, EF]</td>\n","      <td>115</td>\n","      <td>123</td>\n","      <td>the ERP data: BIBREF0</td>\n","      <td>[▁the, ▁, ERP, ▁data, :, ▁, BI, BR, EF]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>-0.500149</td>\n","      <td>461</td>\n","      <td>464</td>\n","      <td>20K news articles</td>\n","      <td>[▁20, K, ▁news, ▁articles]</td>\n","      <td>461</td>\n","      <td>461</td>\n","      <td>20K</td>\n","      <td>[▁20]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>-4.715342</td>\n","      <td>88</td>\n","      <td>91</td>\n","      <td>20K news articles</td>\n","      <td>[▁20, K, ▁news, ▁articles]</td>\n","      <td>88</td>\n","      <td>88</td>\n","      <td>20K</td>\n","      <td>[▁20]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>2.212003</td>\n","      <td>168</td>\n","      <td>173</td>\n","      <td>WW BIBREF19</td>\n","      <td>[WW, ▁, BI, BR, EF, 19]</td>\n","      <td>168</td>\n","      <td>167</td>\n","      <td>WW</td>\n","      <td>[]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>-5.827104</td>\n","      <td>349</td>\n","      <td>360</td>\n","      <td>CoNLL-YAGO BIBREF22</td>\n","      <td>[▁Co, N, LL, -, Y, A, GO, ▁, BI, BR, EF, 22]</td>\n","      <td>349</td>\n","      <td>355</td>\n","      <td>CoNLL-YAGO</td>\n","      <td>[▁Co, N, LL, -, Y, A, GO]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>-2.593458</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>TAC2010</td>\n","      <td>[▁T, AC, 2010]</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>TAC2010</td>\n","      <td>[▁T, AC, 2010]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>10.192525</td>\n","      <td>225</td>\n","      <td>306</td>\n","      <td>rhetorical annotation scheme which takes into ...</td>\n","      <td>[▁rhetorical, ▁annotation, ▁scheme, ▁which, ▁t...</td>\n","      <td>271</td>\n","      <td>276</td>\n","      <td>ated sentences with their rhetorical status</td>\n","      <td>[ated, ▁sentences, ▁with, ▁their, ▁rhetorical,...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>4.036395</td>\n","      <td>301</td>\n","      <td>308</td>\n","      <td>position of sentence, sentence length and tense</td>\n","      <td>[▁position, ▁of, ▁sentence, ,, ▁sentence, ▁len...</td>\n","      <td>301</td>\n","      <td>303</td>\n","      <td>position of sentence,</td>\n","      <td>[▁position, ▁of, ▁sentence]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>3.068229</td>\n","      <td>282</td>\n","      <td>308</td>\n","      <td>a dataset of 20194 cleaned, unique tweets iden...</td>\n","      <td>[▁a, ▁dataset, ▁of, ▁2019, 4, ▁cleaned, ,, ▁un...</td>\n","      <td>285</td>\n","      <td>308</td>\n","      <td>20194 cleaned, unique tweets identified as eit...</td>\n","      <td>[▁2019, 4, ▁cleaned, ,, ▁unique, ▁tweet, s, ▁i...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>-2.845131</td>\n","      <td>260</td>\n","      <td>283</td>\n","      <td>Books (B), DVDs (D), Electronics (E) and Kitch...</td>\n","      <td>[▁Books, ▁, (, B, ), ,, ▁DVD, s, ▁, (, D, ), ,...</td>\n","      <td>260</td>\n","      <td>260</td>\n","      <td>Books</td>\n","      <td>[▁Books]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>-1.042876</td>\n","      <td>407</td>\n","      <td>414</td>\n","      <td>Car, Phone, Notebook, Camera</td>\n","      <td>[Car, ,, ▁Phone, ,, ▁Note, book, ,, ▁Camera]</td>\n","      <td>407</td>\n","      <td>414</td>\n","      <td>Car, Phone, Notebook, Camera)</td>\n","      <td>[Car, ,, ▁Phone, ,, ▁Note, book, ,, ▁Camera]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>-0.495009</td>\n","      <td>28</td>\n","      <td>53</td>\n","      <td>BIBREF35, BIBREF36, BIBREF29 (Car, Phone, Note...</td>\n","      <td>[BI, BR, EF, 35, ,, ▁, BI, BR, EF, 36, ,, ▁, B...</td>\n","      <td>46</td>\n","      <td>53</td>\n","      <td>Car, Phone, Notebook, Camera)</td>\n","      <td>[Car, ,, ▁Phone, ,, ▁Note, book, ,, ▁Camera]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>-1.110858</td>\n","      <td>480</td>\n","      <td>500</td>\n","      <td>raw text, text cleaning through document logic...</td>\n","      <td>[▁raw, ▁text, ,, ▁text, ▁cleaning, ▁through, ▁...</td>\n","      <td>480</td>\n","      <td>481</td>\n","      <td>raw text,</td>\n","      <td>[▁raw, ▁text]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>-2.618403</td>\n","      <td>109</td>\n","      <td>129</td>\n","      <td>raw text, text cleaning through document logic...</td>\n","      <td>[▁raw, ▁text, ,, ▁text, ▁cleaning, ▁through, ▁...</td>\n","      <td>109</td>\n","      <td>110</td>\n","      <td>raw text,</td>\n","      <td>[▁raw, ▁text]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>1.635480</td>\n","      <td>156</td>\n","      <td>174</td>\n","      <td>12 subtrees with 5247 synsets and 3. 2 million...</td>\n","      <td>[▁12, ▁sub, tree, s, ▁with, ▁52, 47, ▁, syn, s...</td>\n","      <td>125</td>\n","      <td>140</td>\n","      <td>tens of millions of annotated images organized...</td>\n","      <td>[▁tens, ▁of, ▁millions, ▁of, ▁an, not, ated, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>2.167394</td>\n","      <td>491</td>\n","      <td>494</td>\n","      <td>SemEval 2019</td>\n","      <td>[▁Sem, E, val, ▁2019]</td>\n","      <td>128</td>\n","      <td>141</td>\n","      <td>datasets given on the shared task, without usi...</td>\n","      <td>[▁dataset, s, ▁given, ▁on, ▁the, ▁shared, ▁tas...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>-3.222356</td>\n","      <td>184</td>\n","      <td>187</td>\n","      <td>F1-score</td>\n","      <td>[▁F, 1, -, score]</td>\n","      <td>178</td>\n","      <td>187</td>\n","      <td>For task 1, we use F1-score</td>\n","      <td>[▁For, ▁task, ▁1, ,, ▁we, ▁use, ▁F, 1, -, score]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>-2.512972</td>\n","      <td>284</td>\n","      <td>286</td>\n","      <td>Task completion ratio</td>\n","      <td>[▁Task, ▁completion, ▁ratio]</td>\n","      <td>284</td>\n","      <td>286</td>\n","      <td>Task completion ratio:</td>\n","      <td>[▁Task, ▁completion, ▁ratio]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>8.621204</td>\n","      <td>14</td>\n","      <td>40</td>\n","      <td>Guidance ability for out of scope input: There...</td>\n","      <td>[▁Gui, d, ance, ▁ability, ▁for, ▁out, ▁of, ▁sc...</td>\n","      <td>14</td>\n","      <td>22</td>\n","      <td>Guidance ability for out of scope input:</td>\n","      <td>[▁Gui, d, ance, ▁ability, ▁for, ▁out, ▁of, ▁sc...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>3.157374</td>\n","      <td>423</td>\n","      <td>435</td>\n","      <td>rodent uterotrophic bioassay data extracted fr...</td>\n","      <td>[▁rodent, ▁, uter, o, trophic, ▁bio, assa, y, ...</td>\n","      <td>410</td>\n","      <td>431</td>\n","      <td>a curated database of high-quality in vivo rod...</td>\n","      <td>[▁a, ▁, cur, ated, ▁database, ▁of, ▁high, -, q...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>0.657291</td>\n","      <td>61</td>\n","      <td>62</td>\n","      <td>research publications</td>\n","      <td>[▁research, ▁publications]</td>\n","      <td>37</td>\n","      <td>58</td>\n","      <td>a curated database of high-quality in vivo rod...</td>\n","      <td>[▁a, ▁, cur, ated, ▁database, ▁of, ▁high, -, q...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>0.856071</td>\n","      <td>154</td>\n","      <td>164</td>\n","      <td>PDFs were provided to us by the database creators</td>\n","      <td>[▁PDF, s, ▁were, ▁provided, ▁to, ▁us, ▁by, ▁th...</td>\n","      <td>18</td>\n","      <td>53</td>\n","      <td>GL and non-GL studies consists of 670 publicat...</td>\n","      <td>[GL, ▁and, ▁non, -, GL, ▁studies, ▁consists, ▁...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>1.430742</td>\n","      <td>469</td>\n","      <td>483</td>\n","      <td>no impact, low impact, medium impact, high imp...</td>\n","      <td>[▁no, ▁impact, ,, ▁low, ▁impact, ,, ▁medium, ▁...</td>\n","      <td>460</td>\n","      <td>483</td>\n","      <td>5 possible impact labels for a particular clai...</td>\n","      <td>[▁5, ▁possible, ▁impact, ▁labels, ▁for, ▁a, ▁p...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>2.467003</td>\n","      <td>97</td>\n","      <td>111</td>\n","      <td>no impact, low impact, medium impact, high imp...</td>\n","      <td>[▁no, ▁impact, ,, ▁low, ▁impact, ,, ▁medium, ▁...</td>\n","      <td>88</td>\n","      <td>111</td>\n","      <td>5 possible impact labels for a particular clai...</td>\n","      <td>[▁5, ▁possible, ▁impact, ▁labels, ▁for, ▁a, ▁p...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>3.897552</td>\n","      <td>39</td>\n","      <td>248</td>\n","      <td>MLQA is a multi-way parallel extractive QA eva...</td>\n","      <td>[ML, Q, A, ▁is, ▁a, ▁multi, -, way, ▁parallel,...</td>\n","      <td>188</td>\n","      <td>249</td>\n","      <td>The resulting corpus has between 5,000 and 6,0...</td>\n","      <td>[▁The, ▁resulting, ▁corpus, ▁has, ▁between, ▁5...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>3.779297</td>\n","      <td>69</td>\n","      <td>80</td>\n","      <td>we proposed a dataset for emotion classificati...</td>\n","      <td>[▁we, ▁proposed, ▁a, ▁dataset, ▁for, ▁emotion,...</td>\n","      <td>9</td>\n","      <td>63</td>\n","      <td>Sundanese is the second-largest tribe in Indon...</td>\n","      <td>[▁Sun, dan, ese, ▁is, ▁the, ▁second, -, larges...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>0.375621</td>\n","      <td>357</td>\n","      <td>370</td>\n","      <td>randomly assigning any of the sentiment values...</td>\n","      <td>[▁randomly, ▁assign, ing, ▁any, ▁of, ▁the, ▁se...</td>\n","      <td>357</td>\n","      <td>370</td>\n","      <td>randomly assigning any of the sentiment values...</td>\n","      <td>[▁randomly, ▁assign, ing, ▁any, ▁of, ▁the, ▁se...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>-0.204527</td>\n","      <td>334</td>\n","      <td>339</td>\n","      <td>English, Arabic, and Spanish</td>\n","      <td>[▁English, ,, ▁Arabic, ,, ▁and, ▁Spanish]</td>\n","      <td>334</td>\n","      <td>334</td>\n","      <td>English,</td>\n","      <td>[▁English]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>1.956522</td>\n","      <td>205</td>\n","      <td>205</td>\n","      <td>Spanish</td>\n","      <td>[▁Spanish]</td>\n","      <td>259</td>\n","      <td>259</td>\n","      <td>English</td>\n","      <td>[▁English]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>-1.954571</td>\n","      <td>204</td>\n","      <td>207</td>\n","      <td>ancient Chinese history records</td>\n","      <td>[▁ancient, ▁Chinese, ▁history, ▁records]</td>\n","      <td>204</td>\n","      <td>230</td>\n","      <td>ancient Chinese history records in several dyn...</td>\n","      <td>[▁ancient, ▁Chinese, ▁history, ▁records, ▁in, ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>10.917922</td>\n","      <td>107</td>\n","      <td>256</td>\n","      <td>manually labeled data. It also improves superv...</td>\n","      <td>[▁manually, ▁labeled, ▁data, ., ▁It, ▁also, ▁i...</td>\n","      <td>21</td>\n","      <td>21</td>\n","      <td>negative</td>\n","      <td>[▁negative]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>-4.409177</td>\n","      <td>393</td>\n","      <td>401</td>\n","      <td>6,138 pieces of logical reasoning questions</td>\n","      <td>[▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...</td>\n","      <td>393</td>\n","      <td>401</td>\n","      <td>6,138 pieces of logical reasoning questions,</td>\n","      <td>[▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>-2.879325</td>\n","      <td>18</td>\n","      <td>26</td>\n","      <td>6,138 pieces of logical reasoning questions</td>\n","      <td>[▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...</td>\n","      <td>18</td>\n","      <td>26</td>\n","      <td>6,138 pieces of logical reasoning questions,</td>\n","      <td>[▁6, ,, 1, 38, ▁pieces, ▁of, ▁logical, ▁reason...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>-1.216578</td>\n","      <td>323</td>\n","      <td>326</td>\n","      <td>6,138</td>\n","      <td>[▁6, ,, 1, 38]</td>\n","      <td>323</td>\n","      <td>329</td>\n","      <td>6,138 logical reasoning questions</td>\n","      <td>[▁6, ,, 1, 38, ▁logical, ▁reasoning, ▁questions]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>6.575477</td>\n","      <td>225</td>\n","      <td>239</td>\n","      <td>It learns the sample weights from the auxiliar...</td>\n","      <td>[▁It, ▁learn, s, ▁the, ▁sample, ▁weight, s, ▁f...</td>\n","      <td>219</td>\n","      <td>221</td>\n","      <td>BIBREF7</td>\n","      <td>[BI, BR, EF]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>169</th>\n","      <td>7.952720</td>\n","      <td>403</td>\n","      <td>447</td>\n","      <td>$(Q^{k},P^{k},A^{k})$ to represent a data poin...</td>\n","      <td>[▁$, (, Q, ^, {, k, }, ,, P, ^, {, k, }, ,, A,...</td>\n","      <td>388</td>\n","      <td>391</td>\n","      <td>BIBREF26</td>\n","      <td>[BI, BR, EF, 26]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>12.889774</td>\n","      <td>182</td>\n","      <td>214</td>\n","      <td>Section \" Experiment Details\" ) using question...</td>\n","      <td>[▁Section, ▁, \", ▁, Experiment, ▁Details, \", ▁...</td>\n","      <td>16</td>\n","      <td>19</td>\n","      <td>BIBREF26</td>\n","      <td>[BI, BR, EF, 26]</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc042a23-d7ec-4211-91a3-0d3f123d4e72')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc042a23-d7ec-4211-91a3-0d3f123d4e72 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc042a23-d7ec-4211-91a3-0d3f123d4e72');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["df_test[:50]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WL17E5Yjhynz","executionInfo":{"status":"ok","timestamp":1653873351324,"user_tz":420,"elapsed":295,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"c94ad8b8-22c3-4ed6-b9a8-165405427d2b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             question  \\\n","0       Which publicly available NLU dataset is used?   \n","1    What profile metadata is used for this analysis?   \n","2         For what purpose was the dataset collected?   \n","3                 What model is used as a baseline?     \n","4                 Which dataset of texts do they use?   \n","5                             What datasets are used?   \n","6                    What is the size of the dataset?   \n","7                         Which datasets do they use?   \n","8                What hand-crafted features are used?   \n","9   What public online harassment datasets was the...   \n","10  What domains are contained in the polarity cla...   \n","11  In what four Chinese review datasets does LCF-...   \n","12  what levels of document preprocessing are look...   \n","13                   What does the dataset represent?   \n","14                           What datasets were used?   \n","15           What metrics are used in the evaluation?   \n","16                  What is the source of their data?   \n","17     What annotations are available in the dataset?   \n","18                   What does the dataset represent?   \n","19        For what purpose was the dataset collected?   \n","20                             what was the baseline?   \n","21  What other languages did they translate the da...   \n","22  Where does the ancient Chinese dataset come from?   \n","23  What are labels available in dataset for super...   \n","24                           How big is this dataset?   \n","25  What is the data selection paper in machine tr...   \n","26   How well does a simple bag-of-words baseline do?   \n","27              What baselines did they compare with?   \n","28                             What metrics are used?   \n","29  What crowdsourcing platform is used for data c...   \n","30                    Which data sources do they use?   \n","31   What two large datasets are used for evaluation?   \n","32                what dataset was used for training?   \n","33                 How big was the dataset presented?   \n","34            What are strong baselines authors used?   \n","35                How large is the released data set?   \n","36       Which dataset do they train their models on?   \n","37                  What is used as a baseline model?   \n","38            Which datasets are used for evaluation?   \n","39                      What are the baseline models?   \n","40                    How big is LibriSpeech dataset?   \n","41                            Who annotated the data?   \n","42                       Which datasets did they use?   \n","43                     How was the dataset collected?   \n","44  To which systems do they compare their results...   \n","45                             what was the baseline?   \n","46  What previously annotated databases are availa...   \n","47                What datasets are used in training?   \n","48  On which dataset(s) do they compute their word...   \n","49                        What news dataset was used?   \n","\n","                                     narrowed_context  \\\n","0   e act and multi-intent. In fact, it is possibl...   \n","1   Users on Twitter are identified with the help ...   \n","2   We present the Stanford Question Answering Dat...   \n","3   Because it is not feasible to collect training...   \n","4   Constituting highly informative network embedd...   \n","5   ifferent representation modalities are thought...   \n","6   zation approaches and obtained encouraging res...   \n","7   ms of the features used for ranking, we classi...   \n","8   In comparison with document summarization on t...   \n","9   covered that ParityBOT played a role in changi...   \n","10  all kernel classifier trained on a source doma...   \n","11  mechanism, takes a more modest strategy compar...   \n","12  The SemEval-2010 benchmark dataset has brought...   \n","13  The explosion of image data on the Internet ha...   \n","14  This paper describes our system, Joint Encoder...   \n","15  rning BIBREF0 , BIBREF1 , BIBREF2 , BIBREF3 , ...   \n","16  al events BIBREF6 or PICO elements BIBREF0 . H...   \n","17  versial topics. The structure of the website d...   \n","18  nchmark datasets. Such annotated datasets are ...   \n","19  Sundanese is the second-largest tribe in Indon...   \n","20  pairs HI-EN and BN-EN are provided for develop...   \n","21  The present study describes our submission to ...   \n","22  ancient characters do not appear in its corres...   \n","23  Recognizing affective events that trigger posi...   \n","24  Recent powerful pre-trained language models ha...   \n","25  We propose a multi-task learning framework to ...   \n","26  We explore the challenge of action prediction ...   \n","27  We propose Sentence Level Recurrent Topic Mode...   \n","28  Nigerian Pidgin is arguably the most widely sp...   \n","29  The Common Voice corpus is a massively-multili...   \n","30  Unsupervised methods for learning distributed ...   \n","31  e attention, which is challenging since there ...   \n","32  opose a framework where language-dependent and...   \n","33  with computer vision techniques that can easil...   \n","34  its WordNet synsets; let $S$ represent the col...   \n","35  This paper advances the state of the art in te...   \n","36  applied that stores only the highest activatio...   \n","37  es. px Equations DISPLAY_FORM11- shows the gaz...   \n","38  Prior work has demonstrated that question clas...   \n","39  h sarcastic content with other topics such as,...   \n","40  xible way to control the context that the mode...   \n","41  y challenging. In this work, we present the ta...   \n","42  serve an interesting pattern in the way senten...   \n","43  The rapid growth of Android apps and its world...   \n","44  overlap with the source sentence. We adapt our...   \n","45  We present a neural-network based approach to ...   \n","46  e two main drawbacks for those classical techn...   \n","47  ntly valuable insights based on single predict...   \n","48  discovery of the optimal negative sample propo...   \n","49  an artificially enlarged dataset, and add new ...   \n","\n","                                            start-end  \\\n","0                                      [(4000, 4014)]   \n","1   [(91, 98), (101, 112), (115, 127), (1661, 1668...   \n","2                                      [(2595, 2672)]   \n","3   [(3123, 3144), (5195, 5200), (1306, 1313), (54...   \n","4      [(1982, 1985), (15358, 15362), (15490, 15494)]   \n","5                                      [(4000, 4020)]   \n","6                                      [(4000, 4002)]   \n","7   [(18723, 18732), (18872, 18878), (18998, 19004...   \n","8   [(5210, 5229), (5232, 5246), (5252, 5256), (53...   \n","9                        [(4000, 4104), (4014, 4104)]   \n","10  [(4000, 4004), (4011, 4014), (4021, 4031), (40...   \n","11                                     [(4000, 4027)]   \n","12         [(2331, 2338), (2341, 2398), (2405, 2456)]   \n","13                                       [(572, 654)]   \n","14                                     [(3450, 3526)]   \n","15  [(4000, 4026), (6014, 6034), (6105, 6128), (62...   \n","16                       [(4000, 4075), (5734, 5869)]   \n","17                                     [(4000, 4118)]   \n","18                                     [(4000, 4287)]   \n","19                                         [(0, 309)]   \n","20                                     [(4000, 4076)]   \n","21                       [(4342, 4349), (1572, 1578)]   \n","22                                     [(4000, 4120)]   \n","23                               [(54, 61), (42, 49)]   \n","24                     [(10324, 10356), (3748, 3790)]   \n","25                     [(2453, 2459), (16012, 16020)]   \n","26                                         [(-1, -1)]   \n","27  [(816, 818), (15373, 15380), (15510, 15513), (...   \n","28                       [(3447, 3456), (3447, 3450)]   \n","29                       [(3408, 3431), (3435, 3445)]   \n","30  [(12906, 12925), (15306, 15330), (15214, 15234...   \n","31                                     [(4000, 4030)]   \n","32  [(4375, 4388), (4703, 4725), (4000, 4017), (43...   \n","33                                     [(4000, 4009)]   \n","34                       [(4000, 4057), (4000, 4084)]   \n","35                                         [(-1, -1)]   \n","36                       [(4000, 4057), (4039, 4065)]   \n","37                                     [(4000, 4048)]   \n","38  [(6722, 6725), (1432, 1435), (13314, 13318), (...   \n","39  [(4000, 4003), (6134, 6136), (16297, 16301), (...   \n","40                                     [(4000, 4135)]   \n","41                       [(4000, 4039), (4706, 4751)]   \n","42  [(4000, 4037), (4053, 4081), (4101, 4131), (40...   \n","43                                     [(1120, 1389)]   \n","44                                     [(4000, 4030)]   \n","45                                     [(2279, 2297)]   \n","46                                     [(4000, 4024)]   \n","47  [(5560, 5579), (7793, 7830), (9043, 9074), (10...   \n","48                                     [(4000, 4043)]   \n","49                                     [(4000, 4075)]   \n","\n","                                               answer  \n","0                                   [ROMULUS dataset]  \n","1   [username, display name, profile image, locati...  \n","2   [To address the need for a large and high-qual...  \n","3   [pre-trained multi-BERT, QANet, BIBREF14, fine...  \n","4                                [Cora, Hepth, Zhihu]  \n","5                             [the ERP data: BIBREF0]  \n","6                                               [20K]  \n","7         [CoNLL-YAGO, TAC2010, ACE2004, AQUAINT, WW]  \n","8   [position of sentence, sentence length, tense,...  \n","9   [20194 cleaned, unique tweets identified as ei...  \n","10     [Books, DVDs, Electronics, Kitchen appliances]  \n","11                     [Car, Phone, Notebook, Camera]  \n","12  [raw text, text cleaning through document logi...  \n","13  [tens of millions of annotated images organize...  \n","14  [datasets given on the shared task, without us...  \n","15  [For task 1, we use F1-score, Task completion ...  \n","16  [a curated database of high-quality in vivo ro...  \n","17  [5 possible impact labels for a particular cla...  \n","18  [The resulting corpus has between 5,000 and 6,...  \n","19  [Sundanese is the second-largest tribe in Indo...  \n","20  [randomly assigning any of the sentiment value...  \n","21                                 [English, English]  \n","22  [ancient Chinese history records in several dy...  \n","23                               [negative, positive]  \n","24  [6,138 logical reasoning questions, 6,138 piec...  \n","25                                [BIBREF7, BIBREF26]  \n","26                                                 []  \n","27  [LDA, Doc-NADE, HTMM, GMNTM, LDA BIBREF2, Doc-...  \n","28                                 [BLEU score, BLEU]  \n","29             [the Common Voice website, iPhone app]  \n","30  [Toronto Books Corpus, STS 2014 dataset BIBREF...  \n","31                  [SParC BIBREF2 and CoSQL BIBREF6]  \n","32  [Amazon reviews, Yelp restaurant reviews, rest...  \n","33                                       [321 videos]  \n","34  [the top 4 predicted labels and the centroid o...  \n","35                                                 []  \n","36  [relation classification dataset of the SemEva...  \n","37  [Neural CRF model with and without ELMo embedd...  \n","38  [ARC, TREC, GARD, MLBioMedLAT, ARC, GARD, MLBi...  \n","39  [ELMo, USE, NBSVM, FastText, XLnet base cased ...  \n","40  [970 hours of audio data with corresponding te...  \n","41  [annotators who were not security experts, res...  \n","42  [Satirical and Legitimate News Database, Rando...  \n","43  [We analyze declared permissions in more than ...  \n","44                  [standard Transformer Base model]  \n","45                              [logistic regression]  \n","46                        [the UBC database BIBREF14]  \n","47  [Arap-Tweet BIBREF19, an in-house Twitter data...  \n","48     [10 million sentences gathered from Wikipedia]  \n","49  [collection of headlines published by HuffPost...  "],"text/html":["\n","  <div id=\"df-d0bcb6de-ade1-4071-8334-ded709930ea6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>narrowed_context</th>\n","      <th>start-end</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Which publicly available NLU dataset is used?</td>\n","      <td>e act and multi-intent. In fact, it is possibl...</td>\n","      <td>[(4000, 4014)]</td>\n","      <td>[ROMULUS dataset]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>What profile metadata is used for this analysis?</td>\n","      <td>Users on Twitter are identified with the help ...</td>\n","      <td>[(91, 98), (101, 112), (115, 127), (1661, 1668...</td>\n","      <td>[username, display name, profile image, locati...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>For what purpose was the dataset collected?</td>\n","      <td>We present the Stanford Question Answering Dat...</td>\n","      <td>[(2595, 2672)]</td>\n","      <td>[To address the need for a large and high-qual...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What model is used as a baseline?</td>\n","      <td>Because it is not feasible to collect training...</td>\n","      <td>[(3123, 3144), (5195, 5200), (1306, 1313), (54...</td>\n","      <td>[pre-trained multi-BERT, QANet, BIBREF14, fine...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Which dataset of texts do they use?</td>\n","      <td>Constituting highly informative network embedd...</td>\n","      <td>[(1982, 1985), (15358, 15362), (15490, 15494)]</td>\n","      <td>[Cora, Hepth, Zhihu]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>What datasets are used?</td>\n","      <td>ifferent representation modalities are thought...</td>\n","      <td>[(4000, 4020)]</td>\n","      <td>[the ERP data: BIBREF0]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>What is the size of the dataset?</td>\n","      <td>zation approaches and obtained encouraging res...</td>\n","      <td>[(4000, 4002)]</td>\n","      <td>[20K]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Which datasets do they use?</td>\n","      <td>ms of the features used for ranking, we classi...</td>\n","      <td>[(18723, 18732), (18872, 18878), (18998, 19004...</td>\n","      <td>[CoNLL-YAGO, TAC2010, ACE2004, AQUAINT, WW]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>What hand-crafted features are used?</td>\n","      <td>In comparison with document summarization on t...</td>\n","      <td>[(5210, 5229), (5232, 5246), (5252, 5256), (53...</td>\n","      <td>[position of sentence, sentence length, tense,...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>What public online harassment datasets was the...</td>\n","      <td>covered that ParityBOT played a role in changi...</td>\n","      <td>[(4000, 4104), (4014, 4104)]</td>\n","      <td>[20194 cleaned, unique tweets identified as ei...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>What domains are contained in the polarity cla...</td>\n","      <td>all kernel classifier trained on a source doma...</td>\n","      <td>[(4000, 4004), (4011, 4014), (4021, 4031), (40...</td>\n","      <td>[Books, DVDs, Electronics, Kitchen appliances]</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>In what four Chinese review datasets does LCF-...</td>\n","      <td>mechanism, takes a more modest strategy compar...</td>\n","      <td>[(4000, 4027)]</td>\n","      <td>[Car, Phone, Notebook, Camera]</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>what levels of document preprocessing are look...</td>\n","      <td>The SemEval-2010 benchmark dataset has brought...</td>\n","      <td>[(2331, 2338), (2341, 2398), (2405, 2456)]</td>\n","      <td>[raw text, text cleaning through document logi...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>What does the dataset represent?</td>\n","      <td>The explosion of image data on the Internet ha...</td>\n","      <td>[(572, 654)]</td>\n","      <td>[tens of millions of annotated images organize...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>What datasets were used?</td>\n","      <td>This paper describes our system, Joint Encoder...</td>\n","      <td>[(3450, 3526)]</td>\n","      <td>[datasets given on the shared task, without us...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>What metrics are used in the evaluation?</td>\n","      <td>rning BIBREF0 , BIBREF1 , BIBREF2 , BIBREF3 , ...</td>\n","      <td>[(4000, 4026), (6014, 6034), (6105, 6128), (62...</td>\n","      <td>[For task 1, we use F1-score, Task completion ...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>What is the source of their data?</td>\n","      <td>al events BIBREF6 or PICO elements BIBREF0 . H...</td>\n","      <td>[(4000, 4075), (5734, 5869)]</td>\n","      <td>[a curated database of high-quality in vivo ro...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>What annotations are available in the dataset?</td>\n","      <td>versial topics. The structure of the website d...</td>\n","      <td>[(4000, 4118)]</td>\n","      <td>[5 possible impact labels for a particular cla...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>What does the dataset represent?</td>\n","      <td>nchmark datasets. Such annotated datasets are ...</td>\n","      <td>[(4000, 4287)]</td>\n","      <td>[The resulting corpus has between 5,000 and 6,...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>For what purpose was the dataset collected?</td>\n","      <td>Sundanese is the second-largest tribe in Indon...</td>\n","      <td>[(0, 309)]</td>\n","      <td>[Sundanese is the second-largest tribe in Indo...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>what was the baseline?</td>\n","      <td>pairs HI-EN and BN-EN are provided for develop...</td>\n","      <td>[(4000, 4076)]</td>\n","      <td>[randomly assigning any of the sentiment value...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>What other languages did they translate the da...</td>\n","      <td>The present study describes our submission to ...</td>\n","      <td>[(4342, 4349), (1572, 1578)]</td>\n","      <td>[English, English]</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Where does the ancient Chinese dataset come from?</td>\n","      <td>ancient characters do not appear in its corres...</td>\n","      <td>[(4000, 4120)]</td>\n","      <td>[ancient Chinese history records in several dy...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>What are labels available in dataset for super...</td>\n","      <td>Recognizing affective events that trigger posi...</td>\n","      <td>[(54, 61), (42, 49)]</td>\n","      <td>[negative, positive]</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>How big is this dataset?</td>\n","      <td>Recent powerful pre-trained language models ha...</td>\n","      <td>[(10324, 10356), (3748, 3790)]</td>\n","      <td>[6,138 logical reasoning questions, 6,138 piec...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>What is the data selection paper in machine tr...</td>\n","      <td>We propose a multi-task learning framework to ...</td>\n","      <td>[(2453, 2459), (16012, 16020)]</td>\n","      <td>[BIBREF7, BIBREF26]</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>How well does a simple bag-of-words baseline do?</td>\n","      <td>We explore the challenge of action prediction ...</td>\n","      <td>[(-1, -1)]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>What baselines did they compare with?</td>\n","      <td>We propose Sentence Level Recurrent Topic Mode...</td>\n","      <td>[(816, 818), (15373, 15380), (15510, 15513), (...</td>\n","      <td>[LDA, Doc-NADE, HTMM, GMNTM, LDA BIBREF2, Doc-...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>What metrics are used?</td>\n","      <td>Nigerian Pidgin is arguably the most widely sp...</td>\n","      <td>[(3447, 3456), (3447, 3450)]</td>\n","      <td>[BLEU score, BLEU]</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>What crowdsourcing platform is used for data c...</td>\n","      <td>The Common Voice corpus is a massively-multili...</td>\n","      <td>[(3408, 3431), (3435, 3445)]</td>\n","      <td>[the Common Voice website, iPhone app]</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Which data sources do they use?</td>\n","      <td>Unsupervised methods for learning distributed ...</td>\n","      <td>[(12906, 12925), (15306, 15330), (15214, 15234...</td>\n","      <td>[Toronto Books Corpus, STS 2014 dataset BIBREF...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>What two large datasets are used for evaluation?</td>\n","      <td>e attention, which is challenging since there ...</td>\n","      <td>[(4000, 4030)]</td>\n","      <td>[SParC BIBREF2 and CoSQL BIBREF6]</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>what dataset was used for training?</td>\n","      <td>opose a framework where language-dependent and...</td>\n","      <td>[(4375, 4388), (4703, 4725), (4000, 4017), (43...</td>\n","      <td>[Amazon reviews, Yelp restaurant reviews, rest...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>How big was the dataset presented?</td>\n","      <td>with computer vision techniques that can easil...</td>\n","      <td>[(4000, 4009)]</td>\n","      <td>[321 videos]</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>What are strong baselines authors used?</td>\n","      <td>its WordNet synsets; let $S$ represent the col...</td>\n","      <td>[(4000, 4057), (4000, 4084)]</td>\n","      <td>[the top 4 predicted labels and the centroid o...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>How large is the released data set?</td>\n","      <td>This paper advances the state of the art in te...</td>\n","      <td>[(-1, -1)]</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Which dataset do they train their models on?</td>\n","      <td>applied that stores only the highest activatio...</td>\n","      <td>[(4000, 4057), (4039, 4065)]</td>\n","      <td>[relation classification dataset of the SemEva...</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>What is used as a baseline model?</td>\n","      <td>es. px Equations DISPLAY_FORM11- shows the gaz...</td>\n","      <td>[(4000, 4048)]</td>\n","      <td>[Neural CRF model with and without ELMo embedd...</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Which datasets are used for evaluation?</td>\n","      <td>Prior work has demonstrated that question clas...</td>\n","      <td>[(6722, 6725), (1432, 1435), (13314, 13318), (...</td>\n","      <td>[ARC, TREC, GARD, MLBioMedLAT, ARC, GARD, MLBi...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>What are the baseline models?</td>\n","      <td>h sarcastic content with other topics such as,...</td>\n","      <td>[(4000, 4003), (6134, 6136), (16297, 16301), (...</td>\n","      <td>[ELMo, USE, NBSVM, FastText, XLnet base cased ...</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>How big is LibriSpeech dataset?</td>\n","      <td>xible way to control the context that the mode...</td>\n","      <td>[(4000, 4135)]</td>\n","      <td>[970 hours of audio data with corresponding te...</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>Who annotated the data?</td>\n","      <td>y challenging. In this work, we present the ta...</td>\n","      <td>[(4000, 4039), (4706, 4751)]</td>\n","      <td>[annotators who were not security experts, res...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Which datasets did they use?</td>\n","      <td>serve an interesting pattern in the way senten...</td>\n","      <td>[(4000, 4037), (4053, 4081), (4101, 4131), (40...</td>\n","      <td>[Satirical and Legitimate News Database, Rando...</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>How was the dataset collected?</td>\n","      <td>The rapid growth of Android apps and its world...</td>\n","      <td>[(1120, 1389)]</td>\n","      <td>[We analyze declared permissions in more than ...</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>To which systems do they compare their results...</td>\n","      <td>overlap with the source sentence. We adapt our...</td>\n","      <td>[(4000, 4030)]</td>\n","      <td>[standard Transformer Base model]</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>what was the baseline?</td>\n","      <td>We present a neural-network based approach to ...</td>\n","      <td>[(2279, 2297)]</td>\n","      <td>[logistic regression]</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>What previously annotated databases are availa...</td>\n","      <td>e two main drawbacks for those classical techn...</td>\n","      <td>[(4000, 4024)]</td>\n","      <td>[the UBC database BIBREF14]</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>What datasets are used in training?</td>\n","      <td>ntly valuable insights based on single predict...</td>\n","      <td>[(5560, 5579), (7793, 7830), (9043, 9074), (10...</td>\n","      <td>[Arap-Tweet BIBREF19, an in-house Twitter data...</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>On which dataset(s) do they compute their word...</td>\n","      <td>discovery of the optimal negative sample propo...</td>\n","      <td>[(4000, 4043)]</td>\n","      <td>[10 million sentences gathered from Wikipedia]</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>What news dataset was used?</td>\n","      <td>an artificially enlarged dataset, and add new ...</td>\n","      <td>[(4000, 4075)]</td>\n","      <td>[collection of headlines published by HuffPost...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0bcb6de-ade1-4071-8334-ded709930ea6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d0bcb6de-ade1-4071-8334-ded709930ea6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d0bcb6de-ade1-4071-8334-ded709930ea6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":116}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dOgCocREtim"},"outputs":[],"source":["test_scores = get_f1_df(test_preds_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1653859480532,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"},"user_tz":420},"id":"KkADOWvFEyGn","outputId":"f0eb7073-7b31-47c0-bd45-1fab5d3f1c8f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   threshold         f1    f1_Answ  f1_NoAnsw\n","6          3  71.161741  37.067771  83.833333"],"text/html":["\n","  <div id=\"df-e3a5070d-3b92-441e-b978-078a0d6f85da\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>f1</th>\n","      <th>f1_Answ</th>\n","      <th>f1_NoAnsw</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>71.161741</td>\n","      <td>37.067771</td>\n","      <td>83.833333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3a5070d-3b92-441e-b978-078a0d6f85da')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e3a5070d-3b92-441e-b978-078a0d6f85da button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e3a5070d-3b92-441e-b978-078a0d6f85da');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":74}],"source":["test_scores[test_scores[\"threshold\"] == threshold] # final score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKPOkCIeeEyu"},"outputs":[],"source":["# Ensemble"]},{"cell_type":"code","source":["best_scibert = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EQaTNhNb7YI","executionInfo":{"status":"ok","timestamp":1653859498719,"user_tz":420,"elapsed":6780,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"bd7ade8d-2d01-44df-85cd-03be591b7da9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177\",\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading weights file /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/SEW.NLP/logs/scibert-squad_24/checkpoint-177.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"]}]},{"cell_type":"code","source":["scibert_trainer = Trainer(\n","    best_scibert,\n","    args,\n","    train_dataset= train_dataset,\n","    eval_dataset= test_dataset,\n","    data_collator=data_collator\n",")\n","\n","val_scibert_predictions = scibert_trainer.predict(val_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"-BopVqIBcOvm","executionInfo":{"status":"error","timestamp":1653859504348,"user_tz":420,"elapsed":432,"user":{"displayName":"Edoardo Botta","userId":"07927463463192486003"}},"outputId":"962e25e9-0b75-4c8b-b37a-899a00426e57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 777\n","  Batch size = 8\n","The following columns in the test set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, df_index. If offset_mapping, df_index are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-76-ef592297a1ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mval_scibert_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscibert_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         output = eval_loop(\n\u001b[0;32m-> 2533\u001b[0;31m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m         )\n\u001b[1;32m   2535\u001b[0m         \u001b[0mtotal_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2636\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2876\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2213\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2216\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m         )\n\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         )\n\u001b[1;32m   1029\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m                 )\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         )\n\u001b[1;32m    500\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."]}]},{"cell_type":"code","source":[""],"metadata":{"id":"o_tzxLuGcSzQ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"best_xlnet_training.ipynb","provenance":[{"file_id":"1KtI_1TWzyC5UGqZiCTDF0zPBP76VFiga","timestamp":1653807099191},{"file_id":"1EVPTX2fO7ET_a7OwcQi2CY1NUgSeHrwy","timestamp":1653779631955},{"file_id":"1fvT8jxYiOjv8S4Mnv5N1M67clU6-GOU5","timestamp":1653682438830},{"file_id":"1XIE0_DsKuta5PQKznSOgJ7hc-wN3q7AO","timestamp":1653456595226}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0bdad832cd3b46a39775bb838c3d9749":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8b83379394e94e80b659269652903a04","IPY_MODEL_7fe8780cf7b74620b3b1e8cd14f55fd4","IPY_MODEL_8895a76eff08415baf78d76051e60acf"],"layout":"IPY_MODEL_ffe2ee0008744f38b8a3071d665f77a6"}},"8b83379394e94e80b659269652903a04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_008347e162044d5a808a5e66b139c4ad","placeholder":"​","style":"IPY_MODEL_cdb9f3cc7bf44f1db7d2973de5cf3544","value":"Downloading: 100%"}},"7fe8780cf7b74620b3b1e8cd14f55fd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_abe691427f934f4194c64eef9b10e368","max":498,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8836060178b64d56bf1b8bee88e63acb","value":498}},"8895a76eff08415baf78d76051e60acf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff5fcdd2e77d4eecb543134fe5fe6263","placeholder":"​","style":"IPY_MODEL_0422e8b3bf224d3fa84cb6771430ec6b","value":" 498/498 [00:00&lt;00:00, 20.8kB/s]"}},"ffe2ee0008744f38b8a3071d665f77a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"008347e162044d5a808a5e66b139c4ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdb9f3cc7bf44f1db7d2973de5cf3544":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abe691427f934f4194c64eef9b10e368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8836060178b64d56bf1b8bee88e63acb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff5fcdd2e77d4eecb543134fe5fe6263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0422e8b3bf224d3fa84cb6771430ec6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f7c93bacf7a48659bd607024b4b66c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17c4572835494bf699d4fc8694793c26","IPY_MODEL_ae66991bca4c475788b9b72fa74ebf5f","IPY_MODEL_9ed95030073d4db9a66e4f8bfabc0a58"],"layout":"IPY_MODEL_5af69b30649546aab8e190b1252684b4"}},"17c4572835494bf699d4fc8694793c26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2a6ded8e2ef4cce912f10e831bd5940","placeholder":"​","style":"IPY_MODEL_cd0d945467fb4fd2a522e747f21a7c99","value":"Downloading: 100%"}},"ae66991bca4c475788b9b72fa74ebf5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab755c51a93e4c049a179ad43208f040","max":2405715,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f590dd46ad0a431f95148dc8bb7df059","value":2405715}},"9ed95030073d4db9a66e4f8bfabc0a58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ee9b8357b0b4830971724454cb8463c","placeholder":"​","style":"IPY_MODEL_eaf568c9e31446ecb8acb5853c8f833a","value":" 2.29M/2.29M [00:01&lt;00:00, 2.59MB/s]"}},"5af69b30649546aab8e190b1252684b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2a6ded8e2ef4cce912f10e831bd5940":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd0d945467fb4fd2a522e747f21a7c99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab755c51a93e4c049a179ad43208f040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f590dd46ad0a431f95148dc8bb7df059":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ee9b8357b0b4830971724454cb8463c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf568c9e31446ecb8acb5853c8f833a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff051b38dd514f3aaba6d9570b09523d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d78760595ff4c55b3c2ac87c1cd300b","IPY_MODEL_e93171f7223c4e2697e72e9e8bb0559c","IPY_MODEL_ad2b93acfa494c26abf11baa8cc1dd4c"],"layout":"IPY_MODEL_ae16f195729345119158ca11ef0f2a5f"}},"4d78760595ff4c55b3c2ac87c1cd300b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df5123e984de4beea445e87643fb1d43","placeholder":"​","style":"IPY_MODEL_883c131010014d51b961aee0c9d9155e","value":"Downloading: 100%"}},"e93171f7223c4e2697e72e9e8bb0559c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_153e30f56e5545829fc9ab0c189fd5fe","max":291,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5ee0c4e222c49b58a6898906edcf207","value":291}},"ad2b93acfa494c26abf11baa8cc1dd4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1546f06cfa51481fb2b40211a26c15ed","placeholder":"​","style":"IPY_MODEL_a056626027c04e0d87207cb7171e2d83","value":" 291/291 [00:00&lt;00:00, 11.6kB/s]"}},"ae16f195729345119158ca11ef0f2a5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df5123e984de4beea445e87643fb1d43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"883c131010014d51b961aee0c9d9155e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"153e30f56e5545829fc9ab0c189fd5fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5ee0c4e222c49b58a6898906edcf207":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1546f06cfa51481fb2b40211a26c15ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a056626027c04e0d87207cb7171e2d83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c74b1339eeea4ae8a62625d6ba70c493":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_631f7eed276a41fe8c97b03e8a9496c1","IPY_MODEL_811343954b704a9495d005326e2ede07","IPY_MODEL_5c23da1e53cd4225bcc77ecf68f3804f"],"layout":"IPY_MODEL_ffa2bbde638b4462ae71a170b5b4b0ce"}},"631f7eed276a41fe8c97b03e8a9496c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36e6547177b045628f11bc5c3f9b0f9c","placeholder":"​","style":"IPY_MODEL_3aa48a26cbc140a29b18553bf5606675","value":"Downloading: 100%"}},"811343954b704a9495d005326e2ede07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b812f1750d1c4d418b2a91aa43a92737","max":945,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c325b86b60ea4d59baddb8eb378f295d","value":945}},"5c23da1e53cd4225bcc77ecf68f3804f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3db8043a7864cd3a661453a90b4120b","placeholder":"​","style":"IPY_MODEL_2e18963d8d6a452384ef40c450701ed1","value":" 945/945 [00:00&lt;00:00, 34.0kB/s]"}},"ffa2bbde638b4462ae71a170b5b4b0ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36e6547177b045628f11bc5c3f9b0f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aa48a26cbc140a29b18553bf5606675":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b812f1750d1c4d418b2a91aa43a92737":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c325b86b60ea4d59baddb8eb378f295d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3db8043a7864cd3a661453a90b4120b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e18963d8d6a452384ef40c450701ed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd9cbb461c0e4842b8d825b6b94c12d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08e647255197495b927e5ba78ab8f130","IPY_MODEL_aa4d0ec6f86a4d6db5968832ed7e9748","IPY_MODEL_b5df0e7f5ece4003bc79ef5a93a35367"],"layout":"IPY_MODEL_191af0232e4e488a932e95739f2eda08"}},"08e647255197495b927e5ba78ab8f130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_296daf131c25433682bf3efa165b8ba9","placeholder":"​","style":"IPY_MODEL_d1624524764d4962bf1153fcbcef328f","value":"Downloading: 100%"}},"aa4d0ec6f86a4d6db5968832ed7e9748":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ade3c3ae6412476e97a09cf4dc11e23d","max":466951457,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82f2d6a4f98a47c88d1bb4716709628a","value":466951457}},"b5df0e7f5ece4003bc79ef5a93a35367":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28e91547633148068a97481551d86027","placeholder":"​","style":"IPY_MODEL_f33a03d30c7d49a08e7c72fb1453ccb1","value":" 445M/445M [00:08&lt;00:00, 65.9MB/s]"}},"191af0232e4e488a932e95739f2eda08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"296daf131c25433682bf3efa165b8ba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1624524764d4962bf1153fcbcef328f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ade3c3ae6412476e97a09cf4dc11e23d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82f2d6a4f98a47c88d1bb4716709628a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28e91547633148068a97481551d86027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f33a03d30c7d49a08e7c72fb1453ccb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}